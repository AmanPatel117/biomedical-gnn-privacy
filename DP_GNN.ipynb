{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-2.8.0+cu126.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-2.8.0+cu126.html\n",
        "!pip install torch-cluster -f https://data.pyg.org/whl/torch-2.8.0+cu126.html\n",
        "!pip install torch-spline-conv -f https://data.pyg.org/whl/torch-2.8.0+cu126.html\n",
        "!pip install torch-geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3b3RTIOYBLK",
        "outputId": "c587e274-9c0b-477d-dcf8-363da36caa94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.8.0+cu126.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.12/dist-packages (2.1.2+pt28cu126)\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.8.0+cu126.html\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.12/dist-packages (0.6.18+pt28cu126)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from torch-sparse) (1.16.3)\n",
            "Requirement already satisfied: numpy<2.6,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from scipy->torch-sparse) (2.0.2)\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.8.0+cu126.html\n",
            "Requirement already satisfied: torch-cluster in /usr/local/lib/python3.12/dist-packages (1.6.3+pt28cu126)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from torch-cluster) (1.16.3)\n",
            "Requirement already satisfied: numpy<2.6,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from scipy->torch-cluster) (2.0.2)\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.8.0+cu126.html\n",
            "Requirement already satisfied: torch-spline-conv in /usr/local/lib/python3.12/dist-packages (1.2.2+pt28cu126)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.12/dist-packages (2.7.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.13.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch-geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2025.11.12)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics\n",
        "!pip install opacus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIFtlzpEYCn1",
        "outputId": "8b7774cf-153b-4cf8-8eab-d85f74bd2ef1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.12/dist-packages (1.8.2)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.0.2)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (25.0)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.9.0+cu126)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (0.15.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.2.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.20.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.3)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.3)\n",
            "Collecting opacus\n",
            "  Downloading opacus-1.5.4-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.12/dist-packages (from opacus) (2.0.2)\n",
            "Requirement already satisfied: torch>=2.0 in /usr/local/lib/python3.12/dist-packages (from opacus) (2.9.0+cu126)\n",
            "Requirement already satisfied: scipy>=1.2 in /usr/local/lib/python3.12/dist-packages (from opacus) (1.16.3)\n",
            "Requirement already satisfied: opt-einsum>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from opacus) (3.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (1.13.3)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0->opacus) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0->opacus) (3.0.3)\n",
            "Downloading opacus-1.5.4-py3-none-any.whl (254 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.4/254.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: opacus\n",
            "Successfully installed opacus-1.5.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SsvnGC4OBCNd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch_geometric.nn import GCNConv, SAGEConv, GATConv\n",
        "import torch_geometric\n",
        "from torch_geometric.nn import global_mean_pool, global_max_pool\n",
        "\n",
        "\n",
        "class FingerprintsModel(torch.nn.M2odule):\n",
        "    def __init__(self, hidden_channels, dataset, model_type:str):\n",
        "        super(FingerprintsModel, self).__init__()\n",
        "        self.model_type = model_type\n",
        "        self.hidden_channels = hidden_channels\n",
        "\n",
        "        if self.model_type == \"GCN\":\n",
        "            self.conv1 = GCNConv(dataset.num_node_features, hidden_channels)\n",
        "            self.conv2 = GCNConv(hidden_channels, hidden_channels*2)\n",
        "            self.conv3 = GCNConv(hidden_channels*2, hidden_channels*4)\n",
        "            # self.conv4 = GCNConv(hidden_channels*4, hidden_channels*8)\n",
        "        elif self.model_type == \"GraphSAGE\":\n",
        "            self.conv1 = SAGEConv(dataset.num_node_features, hidden_channels)\n",
        "            self.conv2 = SAGEConv(hidden_channels, hidden_channels*2)\n",
        "            self.conv3 = SAGEConv(hidden_channels*2, hidden_channels*4)\n",
        "            # self.conv4 = SAGEConv(hidden_channels*4, hidden_channels*8)\n",
        "        elif self.model_type == \"GAT\":\n",
        "            self.conv1 = GATConv(dataset.num_node_features, hidden_channels)\n",
        "            self.conv2 = GATConv(hidden_channels, hidden_channels*2)\n",
        "            self.conv3 = GATConv(hidden_channels*2, hidden_channels*4)\n",
        "            # self.conv4 = GATConv(hidden_channels*4, hidden_channels*8)\n",
        "\n",
        "        self.lin = torch.nn.Sequential(torch.nn.Linear(hidden_channels*4, 256), torch.nn.ReLU(), torch.nn.Linear(256, dataset.num_tasks))\n",
        "        self.norm = torch_geometric.nn.InstanceNorm(1, affine=True)\n",
        "\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        x = self.norm(x, batch)\n",
        "        # 1. Obtain node embeddings\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = x.relu()\n",
        "\n",
        "        # 2. Readout layer\n",
        "        x = global_max_pool(x, batch)  # [batch_size, hidden_channels]\n",
        "\n",
        "        # 3. Apply a final classifier\n",
        "        x = self.lin(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from functorch import jacrev\n",
        "import torch_geometric\n",
        "from functorch import make_functional_with_buffers\n",
        "from opacus.accountants.utils import get_noise_multiplier\n",
        "from opacus.optimizers import DPOptimizer\n",
        "from opacus.utils.batch_memory_manager import wrap_data_loader\n",
        "\n",
        "\n",
        "def train(model, train_loader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "\n",
        "    correct = 0\n",
        "    epoch_loss = 0\n",
        "    for data in tqdm(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        data = data.to(device)\n",
        "        out = model(data.x, data.edge_index, data.batch)\n",
        "        loss = criterion(out, data.y.squeeze())\n",
        "        epoch_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        pred = out.cpu().argmax(dim=1)\n",
        "        correct += int((pred == data.y.squeeze().cpu()).sum())\n",
        "\n",
        "    return epoch_loss/len(train_loader), correct/len(train_loader.dataset)\n",
        "\n",
        "\n",
        "def compute_loss(params, buffers, data_x, data_edge_index, data_batch, targets, fmodel, loss_fn):\n",
        "    predictions = fmodel(params, buffers, data_x, data_edge_index, data_batch)\n",
        "    loss = loss_fn(predictions.squeeze(), targets.squeeze())\n",
        "    return loss\n",
        "\n",
        "\n",
        "# functorch implementation of per sample gradients needed for DP\n",
        "compute_per_sample_grads = jacrev(compute_loss)\n",
        "\n",
        "\n",
        "def train_dp(fmodel, params, buffers, train_loader, device, optimizer, criterion, scheduler=None):\n",
        "    epoch_losses = []\n",
        "    correct = 0\n",
        "\n",
        "    for step, data in enumerate(tqdm(train_loader, desc=\"Iteration\")):\n",
        "        optimizer.zero_grad(True)\n",
        "        data = data.to(device)\n",
        "        out = fmodel(params, buffers, data.x.float(), data.edge_index, data.batch)\n",
        "        pred = out.cpu().argmax(dim=1)\n",
        "        correct += int((pred == data.y.squeeze().cpu()).sum())\n",
        "\n",
        "        if isinstance(criterion, torch.nn.CrossEntropyLoss):\n",
        "            loss = criterion(out.squeeze(), data.y.squeeze())\n",
        "        else:\n",
        "            loss = criterion(out.squeeze(), data.y.squeeze().float().to(device))\n",
        "\n",
        "        per_sample_grads = compute_per_sample_grads(\n",
        "            params,\n",
        "            buffers,\n",
        "            data.x,\n",
        "            data.edge_index,\n",
        "            data.batch,\n",
        "            data.y,\n",
        "            fmodel,\n",
        "            criterion,\n",
        "        )\n",
        "\n",
        "        for param, grad_sample in zip(params, per_sample_grads):\n",
        "            param.grad_sample = grad_sample\n",
        "            param.grad = (grad_sample.mean(0))\n",
        "\n",
        "        optimizer.step()\n",
        "        epoch_losses.append(torch.mean(loss.detach().cpu()))\n",
        "\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "    acc = correct/len(train_loader.dataset)\n",
        "    return np.mean(epoch_losses), acc, params\n",
        "\n",
        "\n",
        "def test(model, test_loader, criterion, device):\n",
        "    model.eval()\n",
        "    epoch_losses = []\n",
        "\n",
        "    correct = 0\n",
        "    for data in tqdm(test_loader):\n",
        "        data = data.to(device)\n",
        "        y = data.y.squeeze()\n",
        "        out = model(data.x, data.edge_index, data.batch)\n",
        "        pred = out.cpu().argmax(dim=1)\n",
        "        correct += int((pred == data.y.squeeze().cpu()).sum())\n",
        "        loss = criterion(out.squeeze(), data.y.squeeze())\n",
        "\n",
        "    epoch_losses.append(torch.mean(loss.detach().cpu()))\n",
        "\n",
        "    return correct/len(test_loader.dataset) , np.mean(epoch_losses)#, f1_score, roc_auc, specificity, sensitivity\n",
        "\n",
        "\n",
        "def set_up_train_environment(dp:bool,\n",
        "                             model:torch.nn.Module,\n",
        "                             nr_train_samples:int,\n",
        "                             epochs:int,\n",
        "                             train_loader:torch_geometric.loader.DataLoader,\n",
        "                             clip:float,\n",
        "                             learning_rate:float,\n",
        "                             batch_size:int,\n",
        "                             max_epsilon:float=None):\n",
        "\n",
        "    fmodel, params, buffers = make_functional_with_buffers(model)\n",
        "\n",
        "    if dp:\n",
        "        optimizer = torch.optim.SGD(params, lr=learning_rate)\n",
        "        criterion = torch.nn.CrossEntropyLoss(reduction=\"none\")\n",
        "        NOISE = get_noise_multiplier(target_epsilon=max_epsilon, target_delta=1/nr_train_samples, sample_rate=1/len(train_loader), epochs=epochs)\n",
        "        optimizer = DPOptimizer(\n",
        "                            optimizer,\n",
        "                            noise_multiplier=NOISE,\n",
        "                            max_grad_norm=clip,\n",
        "                            expected_batch_size=batch_size,\n",
        "                            loss_reduction=\"mean\",\n",
        "                        )\n",
        "        train_loader = wrap_data_loader(data_loader=train_loader, max_batch_size=batch_size, optimizer=optimizer)\n",
        "        torch.set_grad_enabled(False)\n",
        "        return fmodel, params, buffers, optimizer, criterion, train_loader\n",
        "    else:\n",
        "        criterion = torch.nn.CrossEntropyLoss()\n",
        "        optimizer = torch.optim.NAdam(model.parameters(), lr=learning_rate)\n",
        "        torch.set_grad_enabled(True)\n",
        "\n",
        "        return model, params, buffers, optimizer, criterion, train_loader"
      ],
      "metadata": {
        "id": "f2M8869nq-qQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.datasets import TUDataset\n",
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "dataset = TUDataset(root='data/TUD', name='MUTAG')  # 188 graphs\n",
        "\n",
        "#Dataset does not have num_tasks attribute - create it!\n",
        "dataset.num_tasks = 2\n",
        "#dataset.num_node_features = dataset.num_features\n",
        "\n",
        "num_graphs = len(dataset)\n",
        "train = int(0.7*num_graphs)\n",
        "random_idx = torch.randperm(num_graphs)\n",
        "train_idx = random_idx[:train]\n",
        "test_idx = random_idx[train:]\n",
        "\n",
        "train = dataset[train_idx]\n",
        "tester = dataset[test_idx]\n",
        "\n",
        "#Make batches of data\n",
        "trainer = DataLoader(train, batch_size=32,shuffle = True)\n",
        "tester = DataLoader(tester, batch_size=32,shuffle = True)\n",
        "\n",
        "model = FingerprintsModel(16, dataset,\"GCN\").to(device)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "xS3c-AchctBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fmodel, params, buffers, optimizer, criterion, train_loader = set_up_train_environment(dp=True, model = model, nr_train_samples=len(dataset), epochs = 50, train_loader=trainer, clip = 1.0, learning_rate = .01, batch_size = 32, max_epsilon= 5)"
      ],
      "metadata": {
        "id": "Q-zyWOcKdK4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_poch_loss, acc, params = train_dp(fmodel=fmodel, params=params, buffers=buffers, optimizer=optimizer, criterion= criterion, train_loader = train_loader, device = device)"
      ],
      "metadata": {
        "id": "srDmkoX7ieY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_poch_loss"
      ],
      "metadata": {
        "id": "oTMKKQ49iz6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc"
      ],
      "metadata": {
        "id": "h2pb0A9Dk4Lz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sweep for values of epsilon"
      ],
      "metadata": {
        "id": "J2Ms-kJ52aaK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eps = [0.1 ,0.5, 1, 2, 5, 7, 9] #Values of epsilon to test\n",
        "models_trained = dict()\n",
        "\n",
        "for e in eps:\n",
        "  #Initalize Fingerprint model\n",
        "  model = FingerprintsModel(16, dataset,\"GCN\").to(device)\n",
        "  #Set up environment\n",
        "  fmodel, params, buffers, optimizer, criterion, train_loader = set_up_train_environment(dp=True, model = model,\n",
        "                                                                                         nr_train_samples=len(dataset), epochs = 50, train_loader=trainer,\n",
        "                                                                                         clip = 1.0, learning_rate = .01, batch_size = 32, max_epsilon= e)\n",
        "  #Train\n",
        "  mean_epoch_loss, acc, params = train_dp(fmodel=fmodel, params=params, buffers=buffers, optimizer=optimizer,\n",
        "                                         criterion= criterion, train_loader = train_loader, device = device)\n",
        "\n",
        "  print(\"Model with epsilon\", e, \"obtained accuracy\", acc, \"and mean loss\", mean_epoch_loss)\n",
        "\n",
        "  models_trained[e] = model\n",
        "\n",
        "\n",
        "#Epsilon 2 seems to give the best accuracy results"
      ],
      "metadata": {
        "id": "J9RC0aIu2ZR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Try DP-GNN on Test Data\n",
        "* Not necessary since we will use the test data for the shadow model but kept for reference."
      ],
      "metadata": {
        "id": "6ddEe5L04Q2w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_acc, test_mean_loss = test(models_trained[2], tester, criterion, device)"
      ],
      "metadata": {
        "id": "0OQtD_s8k57h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_acc"
      ],
      "metadata": {
        "id": "m91YCU0prW-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_mean_loss"
      ],
      "metadata": {
        "id": "M-vGPhRar1Xn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How does the model hold up to different atacks?\n"
      ],
      "metadata": {
        "id": "ewiFKtCir54x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Member Inference Attack"
      ],
      "metadata": {
        "id": "zfCltGlGsDpK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "omNTMaOZ8IZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = dataset[test_idx]\n",
        "\n",
        "s_num_graphs = len(test_data)\n",
        "train_s = int(0.7*s_num_graphs)\n",
        "random_idx = torch.randperm(s_num_graphs)\n",
        "train_idx = random_idx[:train_s]\n",
        "test_idx = random_idx[train_s:]\n",
        "\n",
        "shadow_train = test_data[train_idx]\n",
        "shadow_tester = test_data[test_idx]\n",
        "\n",
        "#Dataloaders\n",
        "s_trainer = DataLoader(shadow_train, batch_size=32,shuffle = True)\n",
        "s_tester = DataLoader(shadow_tester, batch_size=32,shuffle = True)"
      ],
      "metadata": {
        "id": "1HfMst8fr2s9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s_model = FingerprintsModel(16, test_data,\"GCN\").to(device)"
      ],
      "metadata": {
        "id": "Bo_TmdUVr5Qm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shadow_model, params, buffers, optimizer, criterion, train_loader = set_up_train_environment(dp=True, model = s_model, nr_train_samples=len(test_data), epochs = 50, train_loader=s_trainer, clip = 1.0, learning_rate = .01, batch_size = 32, max_epsilon= 5)\n",
        "shadow_model"
      ],
      "metadata": {
        "id": "mUuqjdn87qnz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_attack_feats(model, dataloader, device):\n",
        "  model.eval()\n",
        "  feats = list()\n",
        "  labels = list()\n",
        "\n",
        "  for data in dataloader:\n",
        "    data = data.to(device)\n",
        "    out = model(data.x, data.edge_index, data.batch)\n",
        "    prob = torch.softmax(out, dim = 1)\n",
        "    max_conf, _ = prob.max(dim=1)\n",
        "    loss = F.cross_entropy(out, data.y.squeeze(), reduction = \"none\")\n",
        "\n",
        "    #Get features and associated label\n",
        "    for max_con, los, ylab in zip( max_conf.cpu(), loss.cpu(), data.y):\n",
        "      feats.append([max_con.item(), los.item()])\n",
        "      #Label\n",
        "      labels.append(ylab)\n",
        "    return torch.tensor(feats), torch.tensor(labels)\n",
        "\n"
      ],
      "metadata": {
        "id": "iZ-998D5Sq8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_attack_feats(shadow_model, train_loader, device)"
      ],
      "metadata": {
        "id": "thZmYRSyVCQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LinkTeller Attack (Failed Attempt)\n",
        "\n",
        "### Follow the pre-processing procedure for one graph from GitHub"
      ],
      "metadata": {
        "id": "AidYQwys8ONb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.utils import to_networkx, dense_to_sparse\n",
        "from torch_geometric.nn import GCNConv\n",
        "import networkx as nx\n",
        "from sklearn.cluster import KMeans\n",
        "import torch, fsspec, torch_geometric\n",
        "from torch_geometric.datasets import TUDataset\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import math, random\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device\n"
      ],
      "metadata": {
        "id": "yZ-tn-tD8TUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = TUDataset(root='data/TUD', name='MUTAG')  # 188 graphs\n",
        "sizes = [data.num_nodes for data in dataset]\n",
        "idx = int(np.argmax([n if n >= 25 else 0 for n in sizes]))  # pick a larger graph\n",
        "data = dataset[idx]\n",
        "print(f\"Graph index {idx}: nodes={data.num_nodes}, edges={data.num_edges // 2} (undirected)\")\n",
        "data.num_tasks = 2\n",
        "data"
      ],
      "metadata": {
        "id": "zilH7GBIFkO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.x.float()  # [N, D]\n",
        "N, D = X.shape\n",
        "\n",
        "\n",
        "K = min(3, len(torch.unique(X, dim=0))) if len(torch.unique(X, dim=0))>1 else 2\n",
        "km = KMeans(n_clusters=K, n_init=10, random_state=0).fit(X.numpy())\n",
        "y_node = torch.from_numpy(km.labels_).long()\n",
        "\n",
        "# Train/val/test node splits\n",
        "idx_all = np.arange(N)\n",
        "idx_train, idx_tmp = train_test_split(idx_all, test_size=0.4, random_state=42, stratify=y_node.numpy())\n",
        "idx_val, idx_test = train_test_split(idx_tmp, test_size=0.5, random_state=42, stratify=y_node.numpy()[idx_tmp])\n",
        "\n",
        "train_mask = torch.zeros(N, dtype=torch.bool); train_mask[idx_train] = True\n",
        "val_mask   = torch.zeros(N, dtype=torch.bool); val_mask[idx_val] = True\n",
        "test_mask  = torch.zeros(N, dtype=torch.bool); test_mask[idx_test] = True\n",
        "\n",
        "print(f\"Splits: train {train_mask.sum().item()}, val {val_mask.sum().item()}, test {test_mask.sum().item()}\")\n",
        "data.train_mask = train_mask\n",
        "data.val_mask = val_mask\n",
        "data.test_mask = test_mask\n",
        "data"
      ],
      "metadata": {
        "id": "4RFmYSWOFoRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Edge index is undirected in PyG; keep it as-is\n",
        "edge_index = data.edge_index  # [2, E]\n",
        "\n",
        "# For evaluation convenience, build a boolean adjacency (without self loops)\n",
        "A = torch.zeros((N, N), dtype=torch.bool)\n",
        "A[edge_index[0], edge_index[1]] = True\n",
        "A[edge_index[1], edge_index[0]] = True\n",
        "A.fill_diagonal_(False)\n",
        "true_edges_undirected = torch.nonzero(torch.triu(A, diagonal=1), as_tuple=False)  # [M, 2]\n",
        "M_true = true_edges_undirected.shape[0]\n",
        "density = M_true / (N*(N-1)/2)\n",
        "print(f\"True undirected edges: {M_true} | density={density:.4f}\")"
      ],
      "metadata": {
        "id": "o5cF8_PBFvm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from functorch import make_functional_with_buffers\n",
        "\n",
        "class GCN(nn.Module):\n",
        "    def __init__(self, in_channels, hidden, out_channels, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden)\n",
        "        self.conv2 = GCNConv(hidden, out_channels)\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def forward(self, x, edge_index, training = True):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=self.dropout, training=training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x  # logits (N, K)\n",
        "\n",
        "model = GCN(D, hidden=32, out_channels=K, dropout=0.2).to(device)\n",
        "X_dev = X.to(device)\n",
        "edge_index_dev = edge_index.to(device)\n",
        "y_dev = y_node.to(device)\n",
        "train_mask_dev = train_mask.to(device)\n",
        "val_mask_dev   = val_mask.to(device)\n",
        "test_mask_dev  = test_mask.to(device)\n",
        "\n",
        "#For manual application of dp\n",
        "model.eval()\n",
        "fmodel, params, buffers = make_functional_with_buffers(model)\n"
      ],
      "metadata": {
        "id": "4VFoma-tGVpU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
