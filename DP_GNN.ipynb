{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-2.8.0+cu126.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-2.8.0+cu126.html\n",
        "!pip install torch-cluster -f https://data.pyg.org/whl/torch-2.8.0+cu126.html\n",
        "!pip install torch-spline-conv -f https://data.pyg.org/whl/torch-2.8.0+cu126.html\n",
        "!pip install torch-geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3b3RTIOYBLK",
        "outputId": "8d9185c4-5a29-4147-f8fb-5f21e51a7ac4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.8.0+cu126.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.12/dist-packages (2.1.2+pt28cu126)\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.8.0+cu126.html\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.12/dist-packages (0.6.18+pt28cu126)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from torch-sparse) (1.16.3)\n",
            "Requirement already satisfied: numpy<2.6,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from scipy->torch-sparse) (2.0.2)\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.8.0+cu126.html\n",
            "Requirement already satisfied: torch-cluster in /usr/local/lib/python3.12/dist-packages (1.6.3+pt28cu126)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from torch-cluster) (1.16.3)\n",
            "Requirement already satisfied: numpy<2.6,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from scipy->torch-cluster) (2.0.2)\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.8.0+cu126.html\n",
            "Requirement already satisfied: torch-spline-conv in /usr/local/lib/python3.12/dist-packages (1.2.2+pt28cu126)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.12/dist-packages (2.7.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.13.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch-geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2025.10.5)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics\n",
        "!pip install opacus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIFtlzpEYCn1",
        "outputId": "4a018bc3-0c1a-47ed-b4b0-b80e6fac0161"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.12/dist-packages (1.8.2)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.0.2)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (25.0)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.8.0+cu126)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (0.15.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.2.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.20.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.3)\n",
            "Requirement already satisfied: opacus in /usr/local/lib/python3.12/dist-packages (1.5.4)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.12/dist-packages (from opacus) (2.0.2)\n",
            "Requirement already satisfied: torch>=2.0 in /usr/local/lib/python3.12/dist-packages (from opacus) (2.8.0+cu126)\n",
            "Requirement already satisfied: scipy>=1.2 in /usr/local/lib/python3.12/dist-packages (from opacus) (1.16.3)\n",
            "Requirement already satisfied: opt-einsum>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from opacus) (3.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0->opacus) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0->opacus) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "SsvnGC4OBCNd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch_geometric.nn import GCNConv, SAGEConv, GATConv\n",
        "import torch_geometric\n",
        "from torch_geometric.nn import global_mean_pool, global_max_pool\n",
        "\n",
        "\n",
        "class FingerprintsModel(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels, dataset, model_type:str):\n",
        "        super(FingerprintsModel, self).__init__()\n",
        "        self.model_type = model_type\n",
        "        self.hidden_channels = hidden_channels\n",
        "\n",
        "        if self.model_type == \"GCN\":\n",
        "            self.conv1 = GCNConv(dataset.num_node_features, hidden_channels)\n",
        "            self.conv2 = GCNConv(hidden_channels, hidden_channels*2)\n",
        "            self.conv3 = GCNConv(hidden_channels*2, hidden_channels*4)\n",
        "            # self.conv4 = GCNConv(hidden_channels*4, hidden_channels*8)\n",
        "        elif self.model_type == \"GraphSAGE\":\n",
        "            self.conv1 = SAGEConv(dataset.num_node_features, hidden_channels)\n",
        "            self.conv2 = SAGEConv(hidden_channels, hidden_channels*2)\n",
        "            self.conv3 = SAGEConv(hidden_channels*2, hidden_channels*4)\n",
        "            # self.conv4 = SAGEConv(hidden_channels*4, hidden_channels*8)\n",
        "        elif self.model_type == \"GAT\":\n",
        "            self.conv1 = GATConv(dataset.num_node_features, hidden_channels)\n",
        "            self.conv2 = GATConv(hidden_channels, hidden_channels*2)\n",
        "            self.conv3 = GATConv(hidden_channels*2, hidden_channels*4)\n",
        "            # self.conv4 = GATConv(hidden_channels*4, hidden_channels*8)\n",
        "\n",
        "        self.lin = torch.nn.Sequential(torch.nn.Linear(hidden_channels*4, 256), torch.nn.ReLU(), torch.nn.Linear(256, dataset.num_tasks))\n",
        "        self.norm = torch_geometric.nn.InstanceNorm(1, affine=True)\n",
        "\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        x = self.norm(x, batch)\n",
        "        # 1. Obtain node embeddings\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = x.relu()\n",
        "\n",
        "        # 2. Readout layer\n",
        "        x = global_max_pool(x, batch)  # [batch_size, hidden_channels]\n",
        "\n",
        "        # 3. Apply a final classifier\n",
        "        x = self.lin(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from functorch import jacrev\n",
        "import torch_geometric\n",
        "from functorch import make_functional_with_buffers\n",
        "from opacus.accountants.utils import get_noise_multiplier\n",
        "from opacus.optimizers import DPOptimizer\n",
        "from opacus.utils.batch_memory_manager import wrap_data_loader\n",
        "\n",
        "\n",
        "def train(model, train_loader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "\n",
        "    correct = 0\n",
        "    epoch_loss = 0\n",
        "    for data in tqdm(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        data = data.to(device)\n",
        "        out = model(data.x, data.edge_index, data.batch)\n",
        "        loss = criterion(out, data.y.squeeze())\n",
        "        epoch_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        pred = out.cpu().argmax(dim=1)\n",
        "        correct += int((pred == data.y.squeeze().cpu()).sum())\n",
        "\n",
        "    return epoch_loss/len(train_loader), correct/len(train_loader.dataset)\n",
        "\n",
        "\n",
        "def compute_loss(params, buffers, data_x, data_edge_index, data_batch, targets, fmodel, loss_fn):\n",
        "    predictions = fmodel(params, buffers, data_x, data_edge_index, data_batch)\n",
        "    loss = loss_fn(predictions.squeeze(), targets.squeeze())\n",
        "    return loss\n",
        "\n",
        "\n",
        "# functorch implementation of per sample gradients needed for DP\n",
        "compute_per_sample_grads = jacrev(compute_loss)\n",
        "\n",
        "\n",
        "def train_dp(fmodel, params, buffers, train_loader, device, optimizer, criterion, scheduler=None):\n",
        "    epoch_losses = []\n",
        "    correct = 0\n",
        "\n",
        "    for step, data in enumerate(tqdm(train_loader, desc=\"Iteration\")):\n",
        "        optimizer.zero_grad(True)\n",
        "        data = data.to(device)\n",
        "        out = fmodel(params, buffers, data.x.float(), data.edge_index, data.batch)\n",
        "        pred = out.cpu().argmax(dim=1)\n",
        "        correct += int((pred == data.y.squeeze().cpu()).sum())\n",
        "\n",
        "        if isinstance(criterion, torch.nn.CrossEntropyLoss):\n",
        "            loss = criterion(out.squeeze(), data.y.squeeze())\n",
        "        else:\n",
        "            loss = criterion(out.squeeze(), data.y.squeeze().float().to(device))\n",
        "\n",
        "        per_sample_grads = compute_per_sample_grads(\n",
        "            params,\n",
        "            buffers,\n",
        "            data.x,\n",
        "            data.edge_index,\n",
        "            data.batch,\n",
        "            data.y,\n",
        "            fmodel,\n",
        "            criterion,\n",
        "        )\n",
        "\n",
        "        for param, grad_sample in zip(params, per_sample_grads):\n",
        "            param.grad_sample = grad_sample\n",
        "            param.grad = (grad_sample.mean(0))\n",
        "\n",
        "        optimizer.step()\n",
        "        epoch_losses.append(torch.mean(loss.detach().cpu()))\n",
        "\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "    acc = correct/len(train_loader.dataset)\n",
        "    return np.mean(epoch_losses), acc, params\n",
        "\n",
        "\n",
        "def test(model, test_loader, criterion, device):\n",
        "    model.eval()\n",
        "    epoch_losses = []\n",
        "\n",
        "    correct = 0\n",
        "    for data in tqdm(test_loader):\n",
        "        data = data.to(device)\n",
        "        y = data.y.squeeze()\n",
        "        out = model(data.x, data.edge_index, data.batch)\n",
        "        pred = out.cpu().argmax(dim=1)\n",
        "        correct += int((pred == data.y.squeeze().cpu()).sum())\n",
        "        loss = criterion(out.squeeze(), data.y.squeeze())\n",
        "\n",
        "    epoch_losses.append(torch.mean(loss.detach().cpu()))\n",
        "\n",
        "    return correct/len(test_loader.dataset) , np.mean(epoch_losses)#, f1_score, roc_auc, specificity, sensitivity\n",
        "\n",
        "\n",
        "def set_up_train_environment(dp:bool,\n",
        "                             model:torch.nn.Module,\n",
        "                             nr_train_samples:int,\n",
        "                             epochs:int,\n",
        "                             train_loader:torch_geometric.loader.DataLoader,\n",
        "                             clip:float,\n",
        "                             learning_rate:float,\n",
        "                             batch_size:int,\n",
        "                             max_epsilon:float=None):\n",
        "\n",
        "    fmodel, params, buffers = make_functional_with_buffers(model)\n",
        "\n",
        "    if dp:\n",
        "        optimizer = torch.optim.SGD(params, lr=learning_rate)\n",
        "        criterion = torch.nn.CrossEntropyLoss(reduction=\"none\")\n",
        "        NOISE = get_noise_multiplier(target_epsilon=max_epsilon, target_delta=1/nr_train_samples, sample_rate=1/len(train_loader), epochs=epochs)\n",
        "        optimizer = DPOptimizer(\n",
        "                            optimizer,\n",
        "                            noise_multiplier=NOISE,\n",
        "                            max_grad_norm=clip,\n",
        "                            expected_batch_size=batch_size,\n",
        "                            loss_reduction=\"mean\",\n",
        "                        )\n",
        "        train_loader = wrap_data_loader(data_loader=train_loader, max_batch_size=batch_size, optimizer=optimizer)\n",
        "        torch.set_grad_enabled(False)\n",
        "        return fmodel, params, buffers, optimizer, criterion, train_loader\n",
        "    else:\n",
        "        criterion = torch.nn.CrossEntropyLoss()\n",
        "        optimizer = torch.optim.NAdam(model.parameters(), lr=learning_rate)\n",
        "        torch.set_grad_enabled(True)\n",
        "\n",
        "        return model, params, buffers, optimizer, criterion, train_loader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2M8869nq-qQ",
        "outputId": "56755580-4806-4adc-a81b-cc146e05cabe"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1931295595.py:38: FutureWarning: We've integrated functorch into PyTorch. As the final step of the integration, `functorch.jacrev` is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use `torch.func.jacrev` instead; see the PyTorch 2.0 release notes and/or the `torch.func` migration guide for more details https://pytorch.org/docs/main/func.migrating.html\n",
            "  compute_per_sample_grads = jacrev(compute_loss)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.datasets import TUDataset\n",
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "dataset = TUDataset(root='data/TUD', name='MUTAG')  # 188 graphs\n",
        "\n",
        "#Dataset does not have num_tasks attribute - create it!\n",
        "dataset.num_tasks = 2\n",
        "#dataset.num_node_features = dataset.num_features\n",
        "\n",
        "num_graphs = len(dataset)\n",
        "train = int(0.7*num_graphs)\n",
        "random_idx = torch.randperm(num_graphs)\n",
        "train_idx = random_idx[:train]\n",
        "test_idx = random_idx[train:]\n",
        "\n",
        "train = dataset[train_idx]\n",
        "tester = dataset[test_idx]\n",
        "\n",
        "#Make batches of data\n",
        "trainer = DataLoader(train, batch_size=32,shuffle = True)\n",
        "tester = DataLoader(tester, batch_size=32,shuffle = True)\n",
        "\n",
        "model = FingerprintsModel(16, dataset,\"GCN\").to(device)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "xS3c-AchctBZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KoV9bb4Gq3Ki"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A2Rm_R-rqEbW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fmodel, params, buffers, optimizer, criterion, train_loader = set_up_train_environment(dp=True, model = model, nr_train_samples=len(dataset), epochs = 50, train_loader=trainer, clip = 1.0, learning_rate = .01, batch_size = 32, max_epsilon= 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-zyWOcKdK4E",
        "outputId": "dfde8c60-fde7-40bc-f199-0792d5155eaa"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1931295595.py:110: FutureWarning: We've integrated functorch into PyTorch. As the final step of the integration, `functorch.make_functional_with_buffers` is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use `torch.func.functional_call` instead; see the PyTorch 2.0 release notes and/or the `torch.func` migration guide for more details https://pytorch.org/docs/main/func.migrating.html\n",
            "  fmodel, params, buffers = make_functional_with_buffers(model)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean_poch_loss, acc, params = train_dp(fmodel=fmodel, params=params, buffers=buffers, optimizer=optimizer, criterion= criterion, train_loader = train_loader, device = device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srDmkoX7ieY0",
        "outputId": "2b3be713-0cb1-430a-8ee3-934c0f1ab433"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 5/5 [00:01<00:00,  4.50it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean_poch_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTMKKQ49iz6N",
        "outputId": "9241efbb-1447-4829-a21c-9841c0de9a74"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float32(0.6517491)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2pb0A9Dk4Lz",
        "outputId": "16d9523c-9993-432e-bb5c-184572b3f069"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6793893129770993"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_acc, test_mean_loss = test(model, tester, criterion, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OQtD_s8k57h",
        "outputId": "50733d10-be46-49a4-c5aa-5914baef632c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 51.16it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m91YCU0prW-O",
        "outputId": "52f8fa99-59eb-4ad8-eb2a-c764c8863e77"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.631578947368421"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_mean_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-vGPhRar1Xn",
        "outputId": "c78829fc-3905-4c0b-da50-f7402f46b978"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float32(0.64881104)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Observe how this defense holds up against attacks\n"
      ],
      "metadata": {
        "id": "ewiFKtCir54x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Member Inference Attack"
      ],
      "metadata": {
        "id": "zfCltGlGsDpK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1HfMst8fr2s9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Bo_TmdUVr5Qm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}