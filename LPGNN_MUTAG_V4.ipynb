{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#!pip uninstall -y torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric"
      ],
      "metadata": {
        "id": "mjX2CBFRrKic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "id": "W7OS89s1kS8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "vSZZbLpS6mOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__, torch.version.cuda)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8Ko9r4urSjX",
        "outputId": "4e9c9269-5937-4e1d-c1c7-cec1f7ba3158"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.0+cu126 12.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-2.8.0+cu126.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-2.8.0+cu126.html\n",
        "!pip install torch-cluster -f https://data.pyg.org/whl/torch-2.8.0+cu126.html\n",
        "!pip install torch-spline-conv -f https://data.pyg.org/whl/torch-2.8.0+cu126.html\n",
        "!pip install torch-geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_RtwpE6rUMb",
        "outputId": "fbc823c7-22a5-4c71-86d4-5d87244b5971"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.8.0+cu126.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.8.0%2Bcu126/torch_scatter-2.1.2%2Bpt28cu126-cp312-cp312-linux_x86_64.whl (10.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.2+pt28cu126\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.8.0+cu126.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.8.0%2Bcu126/torch_sparse-0.6.18%2Bpt28cu126-cp312-cp312-linux_x86_64.whl (5.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from torch-sparse) (1.16.3)\n",
            "Requirement already satisfied: numpy<2.6,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from scipy->torch-sparse) (2.0.2)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.18+pt28cu126\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.8.0+cu126.html\n",
            "Collecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.8.0%2Bcu126/torch_cluster-1.6.3%2Bpt28cu126-cp312-cp312-linux_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from torch-cluster) (1.16.3)\n",
            "Requirement already satisfied: numpy<2.6,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from scipy->torch-cluster) (2.0.2)\n",
            "Installing collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.6.3+pt28cu126\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.8.0+cu126.html\n",
            "Collecting torch-spline-conv\n",
            "  Downloading https://data.pyg.org/whl/torch-2.8.0%2Bcu126/torch_spline_conv-1.2.2%2Bpt28cu126-cp312-cp312-linux_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-spline-conv\n",
            "Successfully installed torch-spline-conv-1.2.2+pt28cu126\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.7.0-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.13.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch-geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2025.11.12)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.15.0)\n",
            "Downloading torch_geometric-2.7.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_33va5trwbo",
        "outputId": "6dedacbb-6e8d-41da-96aa-0c92025e0dbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.0.2)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (25.0)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.9.0+cu126)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.2.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.20.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.3)\n",
            "Downloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.15.2 torchmetrics-1.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchmetrics\n",
        "print(torchmetrics.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLTklWIzrzqc",
        "outputId": "44924763-a2c8-4492-a4b1-8a5d35d36444"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch_geometric\n",
        "print(torch.__version__, torch.version.cuda)\n",
        "print(torch_geometric.__version__)\n",
        "\n",
        "from torch_geometric.datasets import TUDataset\n",
        "data = TUDataset(root='./data/TUDataset', name='MUTAG')\n",
        "print(data)\n"
      ],
      "metadata": {
        "id": "EqhB-6U1rf6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TvNThSUtTjhr"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn.conv.gcn_conv import gcn_norm\n",
        "#from torch_geometric.utils import accuracy as accuracy_1d\n",
        "from sklearn.metrics import accuracy_score\n",
        "from torch.nn import Dropout, SELU\n",
        "from torch_geometric.nn import MessagePassing, SAGEConv, GCNConv, GATConv\n",
        "from torch_sparse import matmul\n",
        "from torch_geometric.transforms import ToSparseTensor\n",
        "\n",
        "\n",
        "class KProp(MessagePassing):\n",
        "    def __init__(self, steps, aggregator, add_self_loops, normalize, cached, transform=lambda x: x):\n",
        "        super().__init__(aggr=aggregator)\n",
        "        self.transform = transform\n",
        "        self.K = steps\n",
        "        self.add_self_loops = add_self_loops\n",
        "        self.normalize = normalize\n",
        "        self.cached = cached\n",
        "        self._cached_x = None\n",
        "\n",
        "    def forward(self, x, adj_t):\n",
        "        if self._cached_x is None or not self.cached:\n",
        "            self._cached_x = self.neighborhood_aggregation(x, adj_t)\n",
        "\n",
        "        return self._cached_x\n",
        "\n",
        "    def neighborhood_aggregation(self, x, adj_t):\n",
        "        if self.K <= 0:\n",
        "            return x\n",
        "\n",
        "        if self.normalize:\n",
        "            adj_t = gcn_norm(adj_t, add_self_loops=False)\n",
        "\n",
        "        if self.add_self_loops:\n",
        "            adj_t = adj_t.set_diag()\n",
        "\n",
        "        for k in range(self.K):\n",
        "            x = self.propagate(adj_t, x=x)\n",
        "\n",
        "        x = self.transform(x)\n",
        "        return x\n",
        "\n",
        "    def message_and_aggregate(self, adj_t, x):  # noqa\n",
        "        return matmul(adj_t, x, reduce=self.aggr)\n",
        "\n",
        "\n",
        "class GNN(torch.nn.Module):\n",
        "    def __init__(self, dropout):\n",
        "        super().__init__()\n",
        "        self.conv1 = None\n",
        "        self.conv2 = None\n",
        "        self.dropout = Dropout(p=dropout)\n",
        "        self.activation = SELU(inplace=True)\n",
        "\n",
        "    def forward(self, x, adj_t):\n",
        "        x = self.conv1(x, adj_t)\n",
        "        x = self.activation(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.conv2(x, adj_t)\n",
        "        return x\n",
        "\n",
        "\n",
        "class GCN(GNN):\n",
        "    def __init__(self, input_dim, output_dim, hidden_dim, dropout):\n",
        "        super().__init__(dropout)\n",
        "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
        "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
        "\n",
        "\n",
        "class GAT(GNN):\n",
        "    def __init__(self, input_dim, output_dim, hidden_dim, dropout):\n",
        "        super().__init__(dropout)\n",
        "        heads = 4\n",
        "        self.conv1 = GATConv(input_dim, hidden_dim, heads=heads, concat=True)\n",
        "        self.conv2 = GATConv(heads * hidden_dim, output_dim, heads=1, concat=False)\n",
        "\n",
        "\n",
        "class GraphSAGE(GNN):\n",
        "    def __init__(self, input_dim, output_dim, hidden_dim, dropout):\n",
        "        super().__init__(dropout)\n",
        "        self.conv1 = SAGEConv(in_channels=input_dim, out_channels=hidden_dim, normalize=False, root_weight=True)\n",
        "        self.conv2 = SAGEConv(in_channels=hidden_dim, out_channels=output_dim, normalize=False, root_weight=True)\n",
        "\n",
        "\n",
        "class NodeClassifier(torch.nn.Module):\n",
        "    def __init__(self,\n",
        "                 input_dim,\n",
        "                 num_classes,\n",
        "                 model:                 dict(help='backbone GNN model', choices=['gcn', 'sage', 'gat']) = 'sage',\n",
        "                 hidden_dim:            dict(help='dimension of the hidden layers') = 16,\n",
        "                 dropout:               dict(help='dropout rate (between zero and one)') = 0.0,\n",
        "                 x_steps:               dict(help='KProp step parameter for features', option='-kx') = 0,\n",
        "                 y_steps:               dict(help='KProp step parameter for labels', option='-ky') = 0,\n",
        "                 forward_correction:    dict(help='applies forward loss correction', option='--forward') = True,\n",
        "                 ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.x_prop = KProp(steps=x_steps, aggregator='add', add_self_loops=False, normalize=True, cached=True)\n",
        "        self.y_prop = KProp(steps=y_steps, aggregator='add', add_self_loops=False, normalize=True, cached=False,\n",
        "                            transform=torch.nn.Softmax(dim=1))\n",
        "\n",
        "        self.gnn = {'gcn': GCN, 'sage': GraphSAGE, 'gat': GAT}[model](\n",
        "            input_dim=input_dim,\n",
        "            output_dim=num_classes,\n",
        "            hidden_dim=hidden_dim,\n",
        "            dropout=dropout\n",
        "        )\n",
        "\n",
        "        self.cached_yt = None\n",
        "        self.forward_correction = forward_correction\n",
        "\n",
        "    def forward(self, data, return_logits=False):\n",
        "        x, adj_t = data.x, data.adj_t\n",
        "        x = self.x_prop(x, adj_t)\n",
        "        x = self.gnn(x, adj_t)\n",
        "\n",
        "        if return_logits:\n",
        "          return x #Raw logits before softmax - for LinkTeller\n",
        "\n",
        "        p_y_x = F.softmax(x, dim=1)\n",
        "        #print()                                                       # P(y|x')\n",
        "        p_yp_x = torch.matmul(p_y_x, data.T) if self.forward_correction else p_y_x          # P(y'|x')\n",
        "        p_yt_x = self.y_prop(p_yp_x, data.adj_t)                                            # P(y~|x')\n",
        "\n",
        "        return p_y_x, p_yp_x, p_yt_x\n",
        "\n",
        "    def training_step(self, data):\n",
        "        p_y_x, p_yp_x, p_yt_x = self(data)\n",
        "\n",
        "        if self.cached_yt is None:\n",
        "            yp = data.y.float()\n",
        "            yp[data.test_mask] = 0  # to avoid using test labels\n",
        "            self.cached_yt = self.y_prop(yp, data.adj_t)  # y~\n",
        "\n",
        "        loss = self.cross_entropy_loss(p_y=p_yt_x[data.train_mask], y=self.cached_yt[data.train_mask], weighted=False)\n",
        "\n",
        "        metrics = {\n",
        "            'train/loss': loss.item(),\n",
        "            'train/acc': self.accuracy(pred=p_y_x[data.train_mask], target=data.y[data.train_mask]) * 100,\n",
        "        }\n",
        "        #Removed 'train/maxacc': data.T[0, 0].item() * 100,\n",
        "\n",
        "        #print(loss)\n",
        "        return loss, metrics\n",
        "\n",
        "    def validation_step(self, data):\n",
        "        p_y_x, p_yp_x, p_yt_x = self(data)\n",
        "\n",
        "        metrics = {\n",
        "            'val/loss': self.cross_entropy_loss(p_yp_x[data.val_mask], data.y[data.val_mask]).item(),\n",
        "            'val/acc': self.accuracy(pred=p_y_x[data.val_mask], target=data.y[data.val_mask]) * 100,\n",
        "            'test/acc': self.accuracy(pred=p_y_x[data.test_mask], target=data.y[data.test_mask]) * 100,\n",
        "        }\n",
        "\n",
        "        return metrics\n",
        "\n",
        "    @staticmethod\n",
        "    def accuracy(pred, target):\n",
        "        pred = pred.argmax(dim=1) if len(pred.size()) > 1 else pred\n",
        "        target = target.argmax(dim=1) if len(target.size()) > 1 else target\n",
        "        return accuracy_score(target,pred)\n",
        "\n",
        "    @staticmethod\n",
        "    def cross_entropy_loss(p_y, y, weighted=False):\n",
        "        y_onehot = F.one_hot(y.argmax(dim=1))\n",
        "        loss = -torch.log(p_y + 1e-20) * y_onehot\n",
        "        loss *= y if weighted else 1\n",
        "        loss = loss.sum(dim=1).mean()\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import torch\n",
        "from torch.optim import SGD, Adam\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "\n",
        "class Trainer:\n",
        "    def __init__(\n",
        "            self,\n",
        "            optimizer:      dict(help='optimization algorithm', choices=['sgd', 'adam']) = 'adam',\n",
        "            max_epochs:     dict(help='maximum number of training epochs') = 500,\n",
        "            learning_rate:  dict(help='learning rate') = 0.01,\n",
        "            weight_decay:   dict(help='weight decay (L2 penalty)') = 0.0,\n",
        "            patience:       dict(help='early-stopping patience window size') = 0,\n",
        "            device='cuda',\n",
        "            logger=None,\n",
        "    ):\n",
        "        self.optimizer_name = optimizer\n",
        "        self.max_epochs = max_epochs\n",
        "        self.device = device\n",
        "        self.learning_rate = learning_rate\n",
        "        self.weight_decay = weight_decay\n",
        "        self.patience = patience\n",
        "        self.logger = logger\n",
        "        self.model = None\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        if self.optimizer_name == 'sgd':\n",
        "            return SGD(self.model.parameters(), lr=self.learning_rate, weight_decay=self.weight_decay)\n",
        "        elif self.optimizer_name == 'adam':\n",
        "            return Adam(self.model.parameters(), lr=self.learning_rate, weight_decay=self.weight_decay)\n",
        "\n",
        "    def fit(self, model, data):\n",
        "        self.model = model.to(self.device)\n",
        "        data = data.to(self.device)\n",
        "        optimizer = self.configure_optimizers()\n",
        "\n",
        "        num_epochs_without_improvement = 0\n",
        "        best_metrics = None\n",
        "\n",
        "        epoch_progbar = tqdm(range(1, self.max_epochs + 1), desc='Epoch: ', leave=False, position=1, file=sys.stdout)\n",
        "        for epoch in epoch_progbar:\n",
        "            metrics = {'epoch': epoch}\n",
        "            train_metrics = self._train(data, optimizer)\n",
        "            metrics.update(train_metrics)\n",
        "\n",
        "            val_metrics = self._validation(data)\n",
        "            metrics.update(val_metrics)\n",
        "\n",
        "            if self.logger:\n",
        "                self.logger.log(metrics)\n",
        "\n",
        "            #Removed from original best_metrics['val/acc'] < metrics['val/acc'] <= metrics['train/maxacc'] and best_metrics['train/acc'] < metrics['train/acc'] <= 1.05 * metrics['train/maxacc']\n",
        "            if best_metrics is None or metrics['val/loss'] < best_metrics['val/loss'] :\n",
        "                best_metrics = metrics\n",
        "                num_epochs_without_improvement = 0\n",
        "            else:\n",
        "                num_epochs_without_improvement += 1\n",
        "                if num_epochs_without_improvement >= self.patience > 0:\n",
        "                    break\n",
        "\n",
        "            # display metrics on progress bar\n",
        "            epoch_progbar.set_postfix(metrics)\n",
        "\n",
        "        if self.logger:\n",
        "            self.logger.log_summary(best_metrics)\n",
        "\n",
        "        return best_metrics\n",
        "\n",
        "    def _train(self, data, optimizer):\n",
        "        self.model.train()\n",
        "        optimizer.zero_grad()\n",
        "        loss, metrics = self.model.training_step(data)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        return metrics\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def _validation(self, data):\n",
        "        self.model.eval()\n",
        "        return self.model.validation_step(data)"
      ],
      "metadata": {
        "id": "KRGEXDwxuKyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DATA PREPROCESSING METHOD: STITCHING GRAPHS\n",
        "# THIS CODE WAS PART OF AN ATTEMPT TO RUN LPGNN ON MUTAG GRAPHS THAT WERE STICHED TOGETHER\n",
        "# THIS METHOD WAS NOT EFFECTIVE SINCE LINKS BETWEEN DISCONNECTED GRAPHS DO NOT EXIST AND WOULD NEED TO BE ADDED BY USER\n",
        "# THIS WOULD PRODUCE INCORRECT SCORES OF ZERO FROM LINKTELLER CODE\n",
        "\n",
        "# import os\n",
        "# from functools import partial\n",
        "# import pandas as pd\n",
        "# import torch\n",
        "# from torch_geometric.data import Data, InMemoryDataset, download_url\n",
        "# from torch_geometric.datasets import Planetoid\n",
        "# from torch_geometric.transforms import ToSparseTensor #, AddTrainValTestMask\n",
        "# from torch_geometric.utils import to_undirected\n",
        "\n",
        "# #from transforms import Normalize, FilterTopClass\n",
        "\n",
        "# def preprocess (num_graphs = 5, val_ratio  = .25, test_ratio = .25):\n",
        "\n",
        "#         #Get the dataset of interest\n",
        "#         mutag = torch_geometric.datasets.TUDataset(root='./data/TUDataset', name='MUTAG')\n",
        "\n",
        "\n",
        "#         nodeFeats = []\n",
        "#         edges = []\n",
        "#         labels = []\n",
        "\n",
        "#         offset = 0\n",
        "\n",
        "#         for g in mutag[:num_graphs]:\n",
        "#           x = g.x\n",
        "#           edge_index = g.edge_index\n",
        "#           y_graph = g.y.item()\n",
        "\n",
        "#           #Convert graph label to node labels\n",
        "#           y_labels = torch.full((g.num_nodes,), y_graph, dtype = torch.long)\n",
        "\n",
        "#           #Offset edges\n",
        "#           edge_index = edge_index + offset\n",
        "\n",
        "\n",
        "#           nodeFeats.append(x)\n",
        "#           edges.append(edge_index)\n",
        "#           labels.append(y_labels)\n",
        "\n",
        "#           offset += g.num_nodes\n",
        "\n",
        "#         #Combine in one graph\n",
        "#         X = torch.cat(nodeFeats, dim = 0)\n",
        "#         Y = torch.cat(labels, dim = 0 )\n",
        "#         E = torch.cat(edges, dim = 1)\n",
        "#         E = to_undirected(E)\n",
        "\n",
        "#         Y = F.one_hot(Y, num_classes=2).float()\n",
        "\n",
        "#         mutag_graph = Data(x=X, edge_index = E, y = Y)\n",
        "\n",
        "#         edge_index_original = E.clone()\n",
        "\n",
        "#         #Get the number of nodes in the graph\n",
        "#         numNode = mutag_graph.num_nodes\n",
        "\n",
        "#         #Randomize indices\n",
        "#         index = torch.randperm(numNode)\n",
        "\n",
        "#         #Masks\n",
        "#         train_mask = torch.zeros(mutag_graph.num_nodes, dtype=torch.bool)\n",
        "#         val_mask   = torch.zeros(mutag_graph.num_nodes, dtype=torch.bool)\n",
        "#         test_mask  = torch.zeros(mutag_graph.num_nodes, dtype=torch.bool)\n",
        "\n",
        "#         #Get the splits for training, test, and val data\n",
        "#         val_data = int(numNode*val_ratio)\n",
        "#         test_data = int(numNode*test_ratio)\n",
        "#         train_data = numNode - val_data - test_data\n",
        "\n",
        "#         #Get random nodes from the fractions calculated above\n",
        "#         train_index = index[:train_data]\n",
        "#         valid_index = index[train_data: train_data+val_data]\n",
        "#         test_index = index[train_data+val_data:]\n",
        "\n",
        "#         #Assign masks - used in original code\n",
        "#         train_mask[train_index] = True\n",
        "#         test_mask[test_index] = True\n",
        "#         val_mask[valid_index] = True\n",
        "\n",
        "#         #Set masks in data\n",
        "#         mutag_graph.train_mask = train_mask\n",
        "#         mutag_graph.test_mask = test_mask\n",
        "#         mutag_graph.val_mask = val_mask\n",
        "\n",
        "#         mutag_graph = ToSparseTensor()(mutag_graph)\n",
        "\n",
        "#         mutag_graph.edge_index = edge_index_original\n",
        "\n",
        "#         return mutag_graph\n"
      ],
      "metadata": {
        "id": "AtPpvv_-ToX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#LOOKING AT INFORMATION ABOUT THE GRAPH\n",
        "# data = preprocess(num_graphs= 100,val_ratio=0.15, test_ratio=0.15)\n",
        "# print(data)\n",
        "# print(f\"Number of nodes is: {data.num_nodes}\")\n",
        "# print(f\"Number of edges is: {data.num_edges}\")\n",
        "# print(f\"Node feature shape: {data.x.shape}\")\n",
        "# print(f\"Labels: {data.y.shape}\")\n",
        "# print(f\"Unique labels: {data.y.unique()}\")"
      ],
      "metadata": {
        "id": "piUrmqX51nBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.utils import to_networkx, dense_to_sparse\n",
        "from torch_geometric.nn import GCNConv\n",
        "import networkx as nx\n",
        "from sklearn.cluster import KMeans\n",
        "import torch, fsspec, torch_geometric\n",
        "from torch_geometric.datasets import TUDataset\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import math, random\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device\n",
        "\n",
        "\n",
        "#USING CODE FROM TEAMMATES IN GITHUB\n",
        "dataset = TUDataset(root='data/TUD', name='MUTAG')  # 188 graphs\n",
        "sizes = [data.num_nodes for data in dataset]\n",
        "idx = int(np.argmax([n if n >= 25 else 0 for n in sizes]))  # pick a larger graph\n",
        "data = dataset[idx]\n",
        "print(f\"Graph index {idx}: nodes={data.num_nodes}, edges={data.num_edges // 2} (undirected)\")\n",
        "\n",
        "#Keep edges for use in LinkTeller - WHEN CONVERTING TOSPARSETENSOR WE LOSE EDGES\n",
        "edges_linkteller = data.edge_index.clone()\n",
        "\n",
        "\n",
        "X = data.x.float()  # [N, D]\n",
        "N, D = X.shape\n",
        "\n",
        "#print(X)\n",
        "K = min(3, len(torch.unique(X, dim=0))) if len(torch.unique(X, dim=0))>1 else 2\n",
        "km = KMeans(n_clusters=K, n_init=10, random_state=0).fit(X.numpy())\n",
        "y_node = torch.from_numpy(km.labels_).long()\n",
        "num_classes = len(torch.unique(y_node))\n",
        "data.y = F.one_hot(y_node, num_classes=num_classes).float()\n",
        "\n",
        "# Train/val/test node splits\n",
        "idx_all = np.arange(N)\n",
        "idx_train, idx_tmp = train_test_split(idx_all, test_size=0.4, random_state=42, stratify=y_node.numpy())\n",
        "idx_val, idx_test = train_test_split(idx_tmp, test_size=0.5, random_state=42, stratify=y_node.numpy()[idx_tmp])\n",
        "\n",
        "data.train_mask = torch.zeros(N, dtype=torch.bool)\n",
        "data.train_mask[idx_train] = True\n",
        "data.val_mask   = torch.zeros(N, dtype=torch.bool)\n",
        "data.val_mask[idx_val] = True\n",
        "data.test_mask  = torch.zeros(N, dtype=torch.bool)\n",
        "data.test_mask[idx_test] = True\n",
        "\n",
        "print(f\"Splits: train {data.train_mask.sum().item()}, val {data.val_mask.sum().item()}, test {data.test_mask.sum().item()}\")\n",
        "\n",
        "data = ToSparseTensor()(data)\n",
        "data.T = torch.eye(num_classes, dtype=torch.float)  # needed for NodeClassifier\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "data = data.to(device)\n",
        "data\n",
        "\n",
        "# CHECK DETAILS OF THE GRAPH TO MAKE SURE EVERYTHING LOOKS FINE/MAKES SENSE\n",
        "print(\"X shape:\", data.x.shape)           # [28, 7]\n",
        "print(\"y shape:\", data.y.shape)           # [28, 3]\n",
        "print(\"train_mask sum:\", data.train_mask.sum())\n",
        "print(\"val_mask sum:\", data.val_mask.sum())\n",
        "print(\"test_mask sum:\", data.test_mask.sum())\n",
        "print(\"adj_t:\", data.adj_t)"
      ],
      "metadata": {
        "id": "3tn05RJNr8fv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edge_index = edges_linkteller\n",
        "\n",
        "# For evaluation convenience, build a boolean adjacency (without self loops)\n",
        "A = torch.zeros((N, N), dtype=torch.bool)\n",
        "A[edge_index[0], edge_index[1]] = True\n",
        "A[edge_index[1], edge_index[0]] = True\n",
        "A.fill_diagonal_(False)\n",
        "true_edges_undirected = torch.nonzero(torch.triu(A, diagonal=1), as_tuple=False)  # [M, 2]\n",
        "M_true = true_edges_undirected.shape[0]\n",
        "density = M_true / (N*(N-1)/2)\n",
        "print(f\"True undirected edges: {M_true} | density={density:.4f}\")\n"
      ],
      "metadata": {
        "id": "YbodZ_MO3EOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Run model\n",
        "model = NodeClassifier(input_dim = D, num_classes = num_classes, model = \"sage\", hidden_dim = 16, dropout = 0.3, x_steps =  1, y_steps = 1, forward_correction = True)\n",
        "model"
      ],
      "metadata": {
        "id": "LyMDe9KLs-20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(optimizer = \"adam\", max_epochs = 50, learning_rate = 0.01, weight_decay = 0, patience = 5, device = 'cpu')"
      ],
      "metadata": {
        "id": "9nP8BTM_t97v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.loader import DataLoader\n",
        "#train_loader = DataLoader([data], batch_size = 1, shuffle=False)\n",
        "#val_loader = DataLoader([data], batch_size = 1, shuffle=False)\n",
        "metrics = trainer.fit(model, data)\n",
        "print(metrics)"
      ],
      "metadata": {
        "id": "B-8x2tnnnPBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LinkTeller Attempt"
      ],
      "metadata": {
        "id": "8z_JrCcH5e9i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy as sp\n",
        "class Linkteller():\n",
        "      def __init__(self, model, device, test_node_feats, test_edge_idx,\n",
        "                   test_edge_attr = None):\n",
        "        \"\"\"\n",
        "        model: Pretrained model\n",
        "        device: torch.device\n",
        "        test_edge_idx: adjacency matrix for the graph being evaluated\n",
        "        undirected: whether the graph is undirected or not (default: True)\n",
        "        \"\"\"\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "        #graph dataset node features\n",
        "        self.test_node_feats = test_node_feats\n",
        "        self.num_nodes = test_node_feats.shape[0]\n",
        "        self.test_edge_idx = test_edge_idx\n",
        "        self.test_edge_attr = test_edge_attr\n",
        "        #build adjcency matrix for test graph from edge indices\n",
        "        self.test_adj = torch.zeros((self.num_nodes, self.num_nodes), dtype=torch.float)\n",
        "        self.test_adj[test_edge_idx[0], test_edge_idx[1]] = True\n",
        "        self.test_adj[test_edge_idx[1], test_edge_idx[0]] = True\n",
        "        self.test_adj.fill_diagonal_(False)\n",
        "        self.true_edges_undirected = torch.nonzero(torch.triu(self.test_adj,\n",
        "                                                         diagonal=1),\n",
        "                                              as_tuple=False)  # [M, 2]\n",
        "        self.M_true = self.true_edges_undirected.shape[0]\n",
        "        self.density = self.M_true / (self.num_nodes*(self.num_nodes-1)/2)\n",
        "\n",
        "      @torch.no_grad()\n",
        "      def gbb_api(self, node_ids, X_query):\n",
        "          \"\"\"\n",
        "          node_ids: 1D LongTensor of node indices to fetch from output\n",
        "          X_query: (N, D) full feature matrix Bob provides (Alice uses it with her private edge_index)\n",
        "          returns: logits[node_ids] shape (len(node_ids), K)\n",
        "\n",
        "          modified from Linkteller.ipynb\n",
        "          \"\"\"\n",
        "          model.eval()\n",
        "          #reconstruct graph using Bob's provided node features & Alice's edges\n",
        "          if self.test_edge_attr is None:\n",
        "            test_graph = Data(x=X_query, edge_index=self.test_edge_idx)\n",
        "          else:\n",
        "            test_graph = Data(x=X_query,\n",
        "                              edge_index=self.test_edge_idx,\n",
        "                              edge_attr=self.test_edge_attr)\n",
        "\n",
        "          test_graph = ToSparseTensor()(test_graph)\n",
        "\n",
        "          test_graph = test_graph.to(device)\n",
        "\n",
        "          #out, _ , _ = model(test_graph)\n",
        "          out = model(test_graph, return_logits=True) #ADDED THIS TO MAKE NODECLASSIFER RETURN LOGITS INSTEAAD OF SOFTMAX PROBABILITIES\n",
        "          #print(out[:5])\n",
        "\n",
        "          return out[node_ids.to(device)].detach().cpu()\n",
        "\n",
        "      def influence_matrix_for_v(self,v, V_I, X_base, delta=1e-2):\n",
        "          \"\"\"\n",
        "          v: node index (int)\n",
        "          V_I: 1D LongTensor of nodes-of-interest to score against\n",
        "          X_base: (N, D) baseline features\n",
        "          returns: Iv (|V_I|, K) = (P' - P)/delta where rows correspond to u in V_I\n",
        "          \"\"\"\n",
        "          #X_base = X_base.float().to(self.device)\n",
        "\n",
        "          node_ids = V_I\n",
        "          P = self.gbb_api(node_ids, X_base)\n",
        "\n",
        "          Xp = X_base.clone()\n",
        "          Xp[v] = (1.0 + delta) * Xp[v]  # upweight features of v\n",
        "          Pp = self.gbb_api(node_ids, Xp)\n",
        "\n",
        "         #print(P[:5])   # before perturbation\n",
        "          #print(Pp[:5])\n",
        "\n",
        "          Iv = (Pp - P) / delta  # finite-diff approximation\n",
        "          return Iv  # (|V_I|, K)\n",
        "\n",
        "      def linkteller_scores(self, V_C, X_base, delta=1e-2):\n",
        "          \"\"\"\n",
        "          V_C: nodes-of-interest (attack surface) as 1D LongTensor\n",
        "          returns: dict {(u,v): score} for u != v, unordered pairs\n",
        "          \"\"\"\n",
        "\n",
        "          #X_base = X_base.float().to(self.device)\n",
        "\n",
        "          V_C = V_C.cpu()\n",
        "          scores = {}\n",
        "\n",
        "          for j, v in enumerate(V_C.tolist()):\n",
        "              # rows aligned with V_C\n",
        "              Iv = self.influence_matrix_for_v(v,\n",
        "                                               V_C,\n",
        "                                               X_base,\n",
        "                                               delta=delta).numpy()\n",
        "              # influence value of v on each u = ||Iv[u,:]||_2\n",
        "              norms = np.linalg.norm(Iv, axis=1)\n",
        "              for i, u in enumerate(V_C.tolist()):\n",
        "                  if u == v:\n",
        "                      continue\n",
        "                  key = (min(u,v), max(u,v))\n",
        "                  # symmetrical score: max of v→u and u→v will be handled later; accumulate max\n",
        "                  scores[key] = max(scores.get(key, 0.0), float(norms[i]))\n",
        "          return scores"
      ],
      "metadata": {
        "id": "uFr5Esg05lZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "#mutag = torch_geometric.datasets.TUDataset(root='./data/TUDataset', name='MUTAG')\n",
        "#test_graph = preprocess(num_graphs=100) #IN STICHED GRAPH VERSION USED SAMPLE OF 100 GRAPHS\n",
        "\n",
        "#print(data.edge_attr) #EXISTS IN DATA\n",
        "\n",
        "linkteller_MUTAG_LPGNN = Linkteller(model = model,\n",
        "                                  device=device,\n",
        "                                  test_node_feats=data.x,\n",
        "                                  test_edge_idx=edges_linkteller,\n",
        "                                  test_edge_attr=data.edge_attr)\n"
      ],
      "metadata": {
        "id": "XepYHtyr5m0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose attack node set V_C (we’ll use all nodes to make life easy)\n",
        "N = data.x.shape[0]\n",
        "V_C = torch.arange(N, dtype=torch.long)\n",
        "X = data.x\n",
        "scores = linkteller_MUTAG_LPGNN.linkteller_scores(V_C, X, delta=1e-2)\n",
        "\n",
        "# Turn scores into a sorted list\n",
        "sorted_pairs = sorted(scores.items(), key=lambda kv: kv[1], reverse=True)\n",
        "len(sorted_pairs), sorted_pairs[:5] #SCORES CONTINUE TO BE ZERO - UNSURE WHAT PART OF THE CODE IS LEADING TO THIS\n"
      ],
      "metadata": {
        "id": "TuRlYl315zbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#scores"
      ],
      "metadata": {
        "id": "F0oE6I-gqxGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_at_fraction(frac):\n",
        "    m = int(round(frac * (N*(N-1)/2)))\n",
        "    pred = set([pair for (pair, _) in sorted_pairs[:m]])\n",
        "    tp = len(pred & true_edges)\n",
        "    fp = len(pred - true_edges)\n",
        "    fn = len(true_edges - pred)\n",
        "    p = tp / (tp + fp + 1e-12)\n",
        "    r = tp / (tp + fn + 1e-12)\n",
        "    f1 = 2*p*r / (p + r + 1e-12)\n",
        "    return p, r, f1, m\n",
        "density = linkteller_MUTAG_LPGNN.density\n",
        "for frac in [0.5*density, 0.8*density, density, 1.2*density, 1.5*density]:\n",
        "    p, r, f1, m = evaluate_at_fraction(frac)\n",
        "    print(f\"k_hat={frac:.4f}  m={m:3d}  P={p:.3f} R={r:.3f} F1={f1:.3f}\")"
      ],
      "metadata": {
        "id": "ZN9UHIbq65VI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n612Es2DqCUR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
