{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## LINKTELLER: About the paper\n",
        "\n",
        "In this paper, we focus on the edge privacy, and consider a training scenario here the data holder Bob with node features will first send training node features to Alice who owns the adjacency information. Alice will then train\n",
        "a graph neural network (GNN) with the joint information and provide an inference API to Bob. During inference time, Bob is able to provide test node features and query the API to obtain the predictions for test nodes. Under this setting, we first propose a privacy attack LINKTELLER via influence analysis to infer the private edge information held by Alice via designing adversarial queries for Bob."
      ],
      "metadata": {
        "id": "hsDKh7tbG4fL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Libraries"
      ],
      "metadata": {
        "id": "AIXGBlgdC9pe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVe60uwZCywD",
        "outputId": "c18525fb-6444-42a6-b7ef-32f5c5137f7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m780.9/780.9 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m99.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m132.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.8.0+cu126 requires torch==2.8.0, but you have torch 2.3.1+cu121 which is incompatible.\n",
            "torchvision 0.23.0+cu126 requires torch==2.8.0, but you have torch 2.3.1+cu121 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m120.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m93.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/163.8 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip -q install --index-url https://download.pytorch.org/whl/cu121 torch==2.3.1\n",
        "\n",
        "# 2) PyG and companions compiled for torch 2.3.1 + cu121\n",
        "!pip -q install -f https://data.pyg.org/whl/torch-2.3.1+cu121.html \\\n",
        "  torch_geometric==2.5.3 torch_scatter==2.1.2 torch_sparse==0.6.18\n",
        "\n",
        "# 3) Pin fsspec to avoid the LocalFileSystem.mv() signature mismatch\n",
        "!pip -q install --force-reinstall --no-deps fsspec==2023.6.0\n",
        "\n",
        "# (Optional utilities)\n",
        "!pip -q install scikit-learn networkx\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.utils import to_networkx, dense_to_sparse\n",
        "from torch_geometric.nn import GCNConv\n",
        "import networkx as nx\n",
        "from sklearn.cluster import KMeans\n",
        "import torch, fsspec, torch_geometric\n",
        "from torch_geometric.datasets import TUDataset\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import math, random\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGyUZyYnD0KS",
        "outputId": "0c40577a-8551-4cfa-d88c-c15b727ab0fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Dataset"
      ],
      "metadata": {
        "id": "MsuVWOhQEBh_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = TUDataset(root='data/TUD', name='MUTAG')  # 188 graphs\n",
        "sizes = [data.num_nodes for data in dataset]\n",
        "idx = int(np.argmax([n if n >= 25 else 0 for n in sizes]))  # pick a larger graph\n",
        "data = dataset[idx]\n",
        "print(f\"Graph index {idx}: nodes={data.num_nodes}, edges={data.num_edges // 2} (undirected)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOKs7QK-ECmx",
        "outputId": "89490c8d-ebde-4250-fa2e-244972eafa1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://www.chrsmrrs.com/graphkerneldatasets/MUTAG.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph index 5: nodes=28, edges=31 (undirected)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BUild X features"
      ],
      "metadata": {
        "id": "wXqBcZwLHdlX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.x.float()  # [N, D]\n",
        "N, D = X.shape\n",
        "\n",
        "\n",
        "K = min(3, len(torch.unique(X, dim=0))) if len(torch.unique(X, dim=0))>1 else 2\n",
        "km = KMeans(n_clusters=K, n_init=10, random_state=0).fit(X.numpy())\n",
        "y_node = torch.from_numpy(km.labels_).long()\n",
        "\n",
        "# Train/val/test node splits\n",
        "idx_all = np.arange(N)\n",
        "idx_train, idx_tmp = train_test_split(idx_all, test_size=0.4, random_state=42, stratify=y_node.numpy())\n",
        "idx_val, idx_test = train_test_split(idx_tmp, test_size=0.5, random_state=42, stratify=y_node.numpy()[idx_tmp])\n",
        "\n",
        "train_mask = torch.zeros(N, dtype=torch.bool); train_mask[idx_train] = True\n",
        "val_mask   = torch.zeros(N, dtype=torch.bool); val_mask[idx_val] = True\n",
        "test_mask  = torch.zeros(N, dtype=torch.bool); test_mask[idx_test] = True\n",
        "\n",
        "print(f\"Splits: train {train_mask.sum().item()}, val {val_mask.sum().item()}, test {test_mask.sum().item()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qeNoQMQkEMVJ",
        "outputId": "87221675-91ab-4e53-fec3-b86a0838fb78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Splits: train 16, val 6, test 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adjacency (A) helpers"
      ],
      "metadata": {
        "id": "5jFF3umCH1Ps"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Edge index is undirected in PyG; keep it as-is\n",
        "edge_index = data.edge_index  # [2, E]\n",
        "\n",
        "# For evaluation convenience, build a boolean adjacency (without self loops)\n",
        "A = torch.zeros((N, N), dtype=torch.bool)\n",
        "A[edge_index[0], edge_index[1]] = True\n",
        "A[edge_index[1], edge_index[0]] = True\n",
        "A.fill_diagonal_(False)\n",
        "true_edges_undirected = torch.nonzero(torch.triu(A, diagonal=1), as_tuple=False)  # [M, 2]\n",
        "M_true = true_edges_undirected.shape[0]\n",
        "density = M_true / (N*(N-1)/2)\n",
        "print(f\"True undirected edges: {M_true} | density={density:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3dXS5STHQVz",
        "outputId": "91ab0a40-f543-4a6d-839f-8ceb5e528c8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True undirected edges: 31 | density=0.0820\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2 small layer GCN for node classification"
      ],
      "metadata": {
        "id": "Tc-2o0zBJOQb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GCN(nn.Module):\n",
        "    def __init__(self, in_channels, hidden, out_channels, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden)\n",
        "        self.conv2 = GCNConv(hidden, out_channels)\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x  # logits (N, K)\n",
        "\n",
        "model = GCN(D, hidden=32, out_channels=K, dropout=0.2).to(device)\n",
        "X_dev = X.to(device)\n",
        "edge_index_dev = edge_index.to(device)\n",
        "y_dev = y_node.to(device)\n",
        "train_mask_dev = train_mask.to(device)\n",
        "val_mask_dev   = val_mask.to(device)\n",
        "test_mask_dev  = test_mask.to(device)\n"
      ],
      "metadata": {
        "id": "NVlIpN9wHxC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## train the model"
      ],
      "metadata": {
        "id": "DNKKh96lJWCX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "opt = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "best_val, best_state = -1, None\n",
        "\n",
        "for epoch in range(400):\n",
        "    model.train()\n",
        "    opt.zero_grad()\n",
        "    logits = model(X_dev, edge_index_dev)\n",
        "    loss = F.cross_entropy(logits[train_mask_dev], y_dev[train_mask_dev])\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "\n",
        "    # quick val acc\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_pred = logits[val_mask_dev].argmax(dim=1)\n",
        "        val_acc = (val_pred == y_dev[val_mask_dev]).float().mean().item()\n",
        "    if val_acc > best_val:\n",
        "        best_val = val_acc\n",
        "        best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
        "\n",
        "print(f\"Best val acc: {best_val:.3f}\")\n",
        "model.load_state_dict({k: v for k, v in best_state.items()})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhFsvxwfIHPm",
        "outputId": "990c175f-fc94-460c-fab1-5919818ae089"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best val acc: 1.000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Black-box “API” wrapper (returns logits for chosen nodes)"
      ],
      "metadata": {
        "id": "LFOjI6WoJblz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def gbb_api(node_ids, X_query):\n",
        "    \"\"\"\n",
        "    node_ids: 1D LongTensor of node indices to fetch from output\n",
        "    X_query: (N, D) full feature matrix Bob provides (Alice uses it with her private edge_index)\n",
        "    returns: logits[node_ids] shape (len(node_ids), K)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    out = model(X_query.to(device), edge_index_dev)  # full-graph forward\n",
        "    return out[node_ids.to(device)].detach().cpu()\n"
      ],
      "metadata": {
        "id": "Bf0gPG0PJW2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LINKTELLER influence matrix & scoring"
      ],
      "metadata": {
        "id": "wNcRvUAJJfYi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def influence_matrix_for_v(v, V_I, X_base, delta=1e-2):\n",
        "    \"\"\"\n",
        "    v: node index (int)\n",
        "    V_I: 1D LongTensor of nodes-of-interest to score against\n",
        "    X_base: (N, D) baseline features\n",
        "    returns: Iv (|V_I|, K) = (P' - P)/delta where rows correspond to u in V_I\n",
        "    \"\"\"\n",
        "    node_ids = V_I\n",
        "    P = gbb_api(node_ids, X_base)\n",
        "\n",
        "    Xp = X_base.clone()\n",
        "    Xp[v] = (1.0 + delta) * Xp[v]  # upweight features of v\n",
        "    Pp = gbb_api(node_ids, Xp)\n",
        "\n",
        "    Iv = (Pp - P) / delta  # finite-diff approximation\n",
        "    return Iv  # (|V_I|, K)\n",
        "\n",
        "def linkteller_scores(V_C, X_base, delta=1e-2):\n",
        "    \"\"\"\n",
        "    V_C: nodes-of-interest (attack surface) as 1D LongTensor\n",
        "    returns: dict {(u,v): score} for u != v, unordered pairs\n",
        "    \"\"\"\n",
        "    V_C = V_C.cpu()\n",
        "    scores = {}\n",
        "    for j, v in enumerate(V_C.tolist()):\n",
        "        Iv = influence_matrix_for_v(v, V_C, X_base, delta=delta).numpy()  # rows aligned with V_C\n",
        "        # influence value of v on each u = ||Iv[u,:]||_2\n",
        "        norms = np.linalg.norm(Iv, axis=1)\n",
        "        for i, u in enumerate(V_C.tolist()):\n",
        "            if u == v:\n",
        "                continue\n",
        "            key = (min(u,v), max(u,v))\n",
        "            # symmetrical score: max of v→u and u→v will be handled later; accumulate max\n",
        "            scores[key] = max(scores.get(key, 0.0), float(norms[i]))\n",
        "    return scores\n",
        "\n",
        "# Choose attack node set V_C (we’ll use all nodes to make life easy)\n",
        "V_C = torch.arange(N, dtype=torch.long)\n",
        "scores = linkteller_scores(V_C, X, delta=1e-2)\n",
        "\n",
        "# Turn scores into a sorted list\n",
        "sorted_pairs = sorted(scores.items(), key=lambda kv: kv[1], reverse=True)\n",
        "len(sorted_pairs), sorted_pairs[:5]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtGZYAx3Jc9J",
        "outputId": "822f491b-46af-44fa-b559-05b9410cec59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(378,\n",
              " [((16, 17), 1.7930238246917725),\n",
              "  ((16, 18), 1.7930238246917725),\n",
              "  ((25, 26), 1.7930220365524292),\n",
              "  ((25, 27), 1.7930220365524292),\n",
              "  ((19, 20), 1.793013572692871)])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pick top-m pairs using a density belief k̂"
      ],
      "metadata": {
        "id": "rG6_8ujQJnFy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = N\n",
        "m_true = M_true\n",
        "m_belief = int(round(density * (n*(n-1)/2)))\n",
        "\n",
        "pred_edges = set([pair for (pair, _) in sorted_pairs[:m_belief]])\n",
        "\n",
        "# ground truth undirected edges as set of tuples (i,j) with i<j\n",
        "true_edges = set([tuple(e.tolist()) for e in true_edges_undirected])\n",
        "\n",
        "tp = len(pred_edges & true_edges)\n",
        "fp = len(pred_edges - true_edges)\n",
        "fn = len(true_edges - pred_edges)\n",
        "\n",
        "precision = tp / (tp + fp + 1e-12)\n",
        "recall    = tp / (tp + fn + 1e-12)\n",
        "f1        = 2*precision*recall / (precision + recall + 1e-12)\n",
        "print(f\"Precision={precision:.3f} | Recall={recall:.3f} | F1={f1:.3f} | m_belief={m_belief} | true M={m_true}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53EthqnAJjS5",
        "outputId": "5efd6b54-383b-47c6-c40a-75958f4ce49a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision=0.710 | Recall=0.710 | F1=0.710 | m_belief=31 | true M=31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Sweep density belief k̂ to see sensitivity"
      ],
      "metadata": {
        "id": "klEK63GlJrMi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_at_fraction(frac):\n",
        "    m = int(round(frac * (n*(n-1)/2)))\n",
        "    pred = set([pair for (pair, _) in sorted_pairs[:m]])\n",
        "    tp = len(pred & true_edges)\n",
        "    fp = len(pred - true_edges)\n",
        "    fn = len(true_edges - pred)\n",
        "    p = tp / (tp + fp + 1e-12)\n",
        "    r = tp / (tp + fn + 1e-12)\n",
        "    f1 = 2*p*r / (p + r + 1e-12)\n",
        "    return p, r, f1, m\n",
        "\n",
        "for frac in [0.5*density, 0.8*density, density, 1.2*density, 1.5*density]:\n",
        "    p, r, f1, m = evaluate_at_fraction(frac)\n",
        "    print(f\"k_hat={frac:.4f}  m={m:3d}  P={p:.3f} R={r:.3f} F1={f1:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mi6o_tpcJsPB",
        "outputId": "f1e5e267-9d79-4ee6-93ce-9e72f6114fda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k_hat=0.0410  m= 16  P=0.750 R=0.387 F1=0.511\n",
            "k_hat=0.0656  m= 25  P=0.840 R=0.677 F1=0.750\n",
            "k_hat=0.0820  m= 31  P=0.710 R=0.710 F1=0.710\n",
            "k_hat=0.0984  m= 37  P=0.676 R=0.806 F1=0.735\n",
            "k_hat=0.1230  m= 46  P=0.674 R=1.000 F1=0.805\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Try a different $\\Delta$"
      ],
      "metadata": {
        "id": "mA9gQ-x1J6RJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scores_different_delta = linkteller_scores(V_C, X, delta=5e-3)\n",
        "sorted_pairs_2 = sorted(scores_different_delta.items(), key=lambda kv: kv[1], reverse=True)\n",
        "pred_edges_2 = set([pair for (pair, _) in sorted_pairs_2[:m_belief]])\n",
        "\n",
        "tp2 = len(pred_edges_2 & true_edges)\n",
        "fp2 = len(pred_edges_2 - true_edges)\n",
        "fn2 = len(true_edges - pred_edges_2)\n",
        "p2 = tp2 / (tp2 + fp2 + 1e-12)\n",
        "r2 = tp2 / (tp2 + fn2 + 1e-12)\n",
        "f12 = 2*p2*r2 / (p2 + r2 + 1e-12)\n",
        "print(f\"(Δ=5e-3) Precision={p2:.3f} | Recall={r2:.3f} | F1={f12:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bcs0TWwCJu7E",
        "outputId": "f0fb6e07-caa9-40f2-b966-d6cd4255b02a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Δ=5e-3) Precision=0.710 | Recall=0.710 | F1=0.710\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "69TLXsr8J9w8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}