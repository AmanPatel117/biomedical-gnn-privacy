{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip\n",
        "!pip3 install torch==2.3.1 --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip install torch_geometric\n",
        "!pip install torch_cluster torch_scatter -f https://data.pyg.org/whl/torch-2.3.1+cu121.html\n",
        "!pip install gdown"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WiPOxpz077AG",
        "outputId": "7cd8b350-51ed-4d68-a5c7-9f9ca0418622"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (25.3)\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Requirement already satisfied: torch==2.3.1 in /usr/local/lib/python3.12/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (4.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.1) (12.6.85)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.3.1) (3.0.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch==2.3.1) (1.3.0)\n",
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.12/dist-packages (2.7.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.13.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.22.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.12/dist-packages (from yarl<2.0,>=1.17.0->aiohttp->torch_geometric) (3.11)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch_geometric) (4.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch_geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2025.10.5)\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.3.1+cu121.html\n",
            "Requirement already satisfied: torch_cluster in /usr/local/lib/python3.12/dist-packages (1.6.3+pt23cu121)\n",
            "Requirement already satisfied: torch_scatter in /usr/local/lib/python3.12/dist-packages (2.1.2+pt23cu121)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from torch_cluster) (1.16.2)\n",
            "Requirement already satisfied: numpy<2.6,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from scipy->torch_cluster) (2.0.2)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown) (4.13.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown) (3.20.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.12/dist-packages (from gdown) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2025.10.5)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "O6DHFYuOuPMs"
      },
      "outputs": [],
      "source": [
        "!pip -q install --force-reinstall --no-deps fsspec==2023.6.0\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3HRLa8xybnD",
        "outputId": "a241d935-d76b-4c1c-9900-e3fe39e6082e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import random_split\n",
        "from torch_geometric.data import Data, InMemoryDataset, DataLoader\n",
        "from torch_geometric.nn import GINEConv, global_add_pool, global_mean_pool, global_max_pool\n",
        "from torch_geometric.utils import dense_to_sparse\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "from typing import List\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.cluster import KMeans\n",
        "import math, random\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhUf0C-6ul_7",
        "outputId": "a128ba6d-5c51-4870-9e9f-fdd2a974697a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset (TU)"
      ],
      "metadata": {
        "id": "yoHTo7cQwVLf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.datasets import TUDataset\n",
        "dataset = TUDataset(root='data/TUD', name='MUTAG')  # 188 graphs\n",
        "sizes = [data.num_nodes for data in dataset]\n",
        "idx = int(np.argmax([n if n >= 25 else 0 for n in sizes]))  # pick a larger graph\n",
        "data = dataset[idx]\n",
        "print(f\"Graph index {idx}: nodes={data.num_nodes}, edges={data.num_edges // 2} (undirected)\")\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjkjRtfjwFzi",
        "outputId": "de476717-be4b-4d2a-ce70-9fec8f63ae29"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph index 5: nodes=28, edges=31 (undirected)\n",
            "Data(edge_index=[2, 62], x=[28, 7], edge_attr=[62, 4], y=[1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# MUTAG Data Preprocessing\n",
        "Adapted from LinkTeller code for consistency"
      ],
      "metadata": {
        "id": "Yw43-9dW0sS4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = TUDataset(root=\"data/TUDataset\", name=\"MUTAG\", use_node_attr=True)\n",
        "# MUTAG typically has node attributes; if not present, dataset.data.x may be None\n",
        "if dataset.num_node_features == 0:\n",
        "    # fallback: use one-hot of node labels if available, else create constant feature\n",
        "    if dataset.num_node_labels > 0:\n",
        "        print(\"No node features found — using node labels one-hot\")\n",
        "        # transform each graph: replace x by one-hot of node_label (PyG stores node labels in data.x sometimes)\n",
        "        for data in dataset:\n",
        "            # some TUDataset encodes node labels in data.x as integers inside x, or in data.node_label\n",
        "            # here we'll convert data.x (assumed scalar) -> one-hot\n",
        "            if data.x is not None and data.x.dim() == 1:\n",
        "                num_cat = int(data.x.max().item()) + 1\n",
        "                one_hot = F.one_hot(data.x.long(), num_classes=num_cat).to(torch.float)\n",
        "                data.x = one_hot\n",
        "            else:\n",
        "                # create constant feature\n",
        "                data.x = torch.ones((data.num_nodes, 1), dtype=torch.float)\n",
        "    else:\n",
        "        for data in dataset:\n",
        "            data.x = torch.ones((data.num_nodes, 1), dtype=torch.float)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfULAGd6wUqY",
        "outputId": "8cc7c1ad-f3cd-4d67-d106-34a148c5f880"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://www.chrsmrrs.com/graphkerneldatasets/MUTAG.zip\n",
            "Processing...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GIN Model\n",
        "Customizable GINE model built around the pyg GINEConv layer. Use GINE over GIN to train on edge features"
      ],
      "metadata": {
        "id": "BFoAxU4FxoA2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EdgeMLP(nn.Module):\n",
        "    \"\"\"Small MLP to combine node and edge features inside each GINE layer.\"\"\"\n",
        "    def __init__(self, input_dim, hidden_dim, dropout=0.0):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class GINEModel(nn.Module):\n",
        "    def __init__(self, node_input_dim, edge_input_dim, hidden_dim=64,\n",
        "                 num_layers=3, dropout=0.2, num_classes=2):\n",
        "        super().__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.convs = nn.ModuleList()\n",
        "        self.bns = nn.ModuleList()\n",
        "        self.edge_transform = nn.ModuleList()\n",
        "        for i in range(num_layers):\n",
        "            in_dim = node_input_dim if i == 0 else hidden_dim\n",
        "            mlp = EdgeMLP(in_dim, hidden_dim, dropout)\n",
        "            #don't explicitly define edge_dim here; transform edge features into\n",
        "            #the same dimension as the GINE in the forward pass with edge_layer\n",
        "            conv = GINEConv(nn=mlp, train_eps=True)\n",
        "            edge_layer = nn.Linear(edge_input_dim, in_dim)\n",
        "            self.convs.append(conv)\n",
        "            self.bns.append(nn.BatchNorm1d(hidden_dim))\n",
        "            self.edge_transform.append(edge_layer)\n",
        "\n",
        "        self.pool = global_add_pool\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
        "        if edge_attr is None:\n",
        "            #if dataset doesn’t have edge attributes, use zeros\n",
        "            edge_attr = torch.zeros((edge_index.size(1), 1), device=x.device)\n",
        "        for conv, bn, edge_transform in zip(self.convs, self.bns, self.edge_transform):\n",
        "            #transform edge features to match node input dimensions\n",
        "            edge_attr_trans = edge_transform(edge_attr)\n",
        "            x = conv(x, edge_index, edge_attr_trans)\n",
        "            x = bn(x)\n",
        "            x = F.relu(x)\n",
        "        g = self.pool(x, batch)\n",
        "        out = self.classifier(g)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "Z0aPUAmMu1p2"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Utility Functions"
      ],
      "metadata": {
        "id": "cueyxjdSKFQo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, loader, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data)\n",
        "        loss = F.cross_entropy(out, data.y.view(-1).to(device))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * data.num_graphs\n",
        "        preds = out.argmax(dim=1)\n",
        "        correct += (preds == data.y.to(device)).sum().item()\n",
        "        total += data.num_graphs\n",
        "    return total_loss / total, correct / total"
      ],
      "metadata": {
        "id": "4v_APjGPCUgQ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(model, loader, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    total_loss = 0.0\n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "        out = model(data)\n",
        "        loss = F.cross_entropy(out, data.y.view(-1).to(device))\n",
        "        preds = out.argmax(dim=1)\n",
        "        correct += (preds == data.y.to(device)).sum().item()\n",
        "        total += data.num_graphs\n",
        "        total_loss += loss.item() * data.num_graphs\n",
        "    return total_loss / total, correct / total\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uMiiIB7dvBN3"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline Training & Evaluation"
      ],
      "metadata": {
        "id": "lXqrtRV5J6qL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from torch.utils.data import Subset\n",
        "\n",
        "#hyperparams\n",
        "seed = 42\n",
        "epochs = 100\n",
        "batch_size = 32\n",
        "lr = 1e-3\n",
        "weight_decay = 1e-5\n",
        "#initialize random #s\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "X = list(range(len(dataset)))\n",
        "y = np.array([int(dataset[i].y.item()) for i in range(len(dataset))])\n",
        "#StratifiedKFold for cross-validation (90/10 train-test split each time)\n",
        "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "\n",
        "fold_accuracies = []\n",
        "#iterate over each k-fold\n",
        "for fold, (train_idx, test_idx) in enumerate(skf.split(X, y), 1):\n",
        "    print(f\"\\n=== Fold {fold} ===\")\n",
        "    train_subset = Subset(dataset, train_idx)\n",
        "    test_subset = Subset(dataset, test_idx)\n",
        "\n",
        "    train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(test_subset, batch_size=batch_size, shuffle=False)\n",
        "    #reinitialize model from scratch each time\n",
        "    model = GINEModel(node_input_dim=dataset[0].x.shape[1],\n",
        "                      edge_input_dim=dataset[0].edge_attr.shape[1],\n",
        "                      hidden_dim=32, num_layers=2,\n",
        "                      dropout=0.2,\n",
        "                      num_classes=dataset.num_classes).to(device)\n",
        "    optimizer = Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    best_test_acc = 0.0\n",
        "    #iterate over epochs\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        train_loss, train_acc = train_epoch(model, train_loader, optimizer, device)\n",
        "        test_loss, test_acc = evaluate(model, test_loader, device)\n",
        "        if test_acc > best_test_acc:\n",
        "            best_test_acc = test_acc\n",
        "        if epoch % 20 == 0 or epoch == 1 or epoch == epochs:\n",
        "            print(f\"Epoch {epoch:03d} | Train loss {train_loss:.4f} acc {train_acc:.4f} | Test loss {test_loss:.4f} acc {test_acc:.4f}\")\n",
        "    print(f\"Fold {fold} best test acc: {best_test_acc:.4f}\")\n",
        "    fold_accuracies.append(best_test_acc)\n",
        "\n",
        "mean_acc = np.mean(fold_accuracies)\n",
        "std_acc = np.std(fold_accuracies)\n",
        "print(f\"\\n10-fold CV accuracy: {mean_acc:.4f} ± {std_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXgrKCfQJrT2",
        "outputId": "db3daf34-a3bb-4d46-a394-6551fdf8ff36"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Fold 1 ===\n",
            "torch.Size([38, 4]) torch.Size([17, 7])\n",
            "Epoch 001 | Train loss 1.0070 acc 0.6627 | Test loss 0.7204 acc 0.2105\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2908916043.py:29: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
            "/tmp/ipython-input-2908916043.py:30: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  test_loader = DataLoader(test_subset, batch_size=batch_size, shuffle=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 020 | Train loss 0.4377 acc 0.8047 | Test loss 0.8784 acc 0.3158\n",
            "Epoch 040 | Train loss 0.3106 acc 0.8402 | Test loss 1.7432 acc 0.3158\n",
            "Epoch 060 | Train loss 0.3174 acc 0.8580 | Test loss 0.6960 acc 0.7368\n",
            "Epoch 080 | Train loss 0.2738 acc 0.8698 | Test loss 3.3051 acc 0.3158\n",
            "Epoch 100 | Train loss 0.2569 acc 0.8876 | Test loss 0.5477 acc 0.7368\n",
            "Fold 1 best test acc: 1.0000\n",
            "\n",
            "=== Fold 2 ===\n",
            "torch.Size([38, 4]) torch.Size([17, 7])\n",
            "Epoch 001 | Train loss 0.7076 acc 0.6036 | Test loss 0.6345 acc 0.7368\n",
            "Epoch 020 | Train loss 0.3814 acc 0.7751 | Test loss 0.6836 acc 0.5789\n",
            "Epoch 040 | Train loss 0.3019 acc 0.8580 | Test loss 0.7886 acc 0.3684\n",
            "Epoch 060 | Train loss 0.2716 acc 0.8994 | Test loss 1.1395 acc 0.3684\n",
            "Epoch 080 | Train loss 0.2494 acc 0.8876 | Test loss 1.2231 acc 0.3158\n",
            "Epoch 100 | Train loss 0.1823 acc 0.9231 | Test loss 1.4674 acc 0.3158\n",
            "Fold 2 best test acc: 0.8947\n",
            "\n",
            "=== Fold 3 ===\n",
            "torch.Size([38, 4]) torch.Size([17, 7])\n",
            "Epoch 001 | Train loss 0.8095 acc 0.5917 | Test loss 0.5819 acc 0.6842\n",
            "Epoch 020 | Train loss 0.3754 acc 0.7988 | Test loss 1.2016 acc 0.3158\n",
            "Epoch 040 | Train loss 0.3246 acc 0.8462 | Test loss 1.5684 acc 0.3158\n",
            "Epoch 060 | Train loss 0.3050 acc 0.8343 | Test loss 1.4849 acc 0.4211\n",
            "Epoch 080 | Train loss 0.2597 acc 0.8757 | Test loss 1.6777 acc 0.5263\n",
            "Epoch 100 | Train loss 0.1873 acc 0.9231 | Test loss 2.6489 acc 0.3158\n",
            "Fold 3 best test acc: 0.7895\n",
            "\n",
            "=== Fold 4 ===\n",
            "torch.Size([38, 4]) torch.Size([17, 7])\n",
            "Epoch 001 | Train loss 0.6331 acc 0.6509 | Test loss 0.5941 acc 0.6842\n",
            "Epoch 020 | Train loss 0.4059 acc 0.8047 | Test loss 0.8073 acc 0.4211\n",
            "Epoch 040 | Train loss 0.2545 acc 0.8757 | Test loss 0.6518 acc 0.6316\n",
            "Epoch 060 | Train loss 0.2565 acc 0.8994 | Test loss 1.1943 acc 0.3684\n",
            "Epoch 080 | Train loss 0.2950 acc 0.8639 | Test loss 0.9509 acc 0.3158\n",
            "Epoch 100 | Train loss 0.2900 acc 0.8817 | Test loss 0.4979 acc 0.7895\n",
            "Fold 4 best test acc: 0.9474\n",
            "\n",
            "=== Fold 5 ===\n",
            "torch.Size([38, 4]) torch.Size([17, 7])\n",
            "Epoch 001 | Train loss 1.0482 acc 0.5740 | Test loss 0.5865 acc 0.6842\n",
            "Epoch 020 | Train loss 0.4113 acc 0.8107 | Test loss 0.5085 acc 0.7895\n",
            "Epoch 040 | Train loss 0.3165 acc 0.8343 | Test loss 0.4469 acc 0.8421\n",
            "Epoch 060 | Train loss 0.2806 acc 0.8639 | Test loss 0.5153 acc 0.6842\n",
            "Epoch 080 | Train loss 0.2153 acc 0.9053 | Test loss 0.4434 acc 0.6842\n",
            "Epoch 100 | Train loss 0.2206 acc 0.9112 | Test loss 0.5014 acc 0.6842\n",
            "Fold 5 best test acc: 0.8947\n",
            "\n",
            "=== Fold 6 ===\n",
            "torch.Size([38, 4]) torch.Size([17, 7])\n",
            "Epoch 001 | Train loss 0.7750 acc 0.5858 | Test loss 0.6373 acc 0.6316\n",
            "Epoch 020 | Train loss 0.3522 acc 0.8343 | Test loss 0.3586 acc 0.8947\n",
            "Epoch 040 | Train loss 0.2937 acc 0.8876 | Test loss 0.4682 acc 0.7895\n",
            "Epoch 060 | Train loss 0.2713 acc 0.8935 | Test loss 0.6501 acc 0.6842\n",
            "Epoch 080 | Train loss 0.2719 acc 0.8521 | Test loss 0.9454 acc 0.6316\n",
            "Epoch 100 | Train loss 0.2225 acc 0.8876 | Test loss 1.1367 acc 0.6316\n",
            "Fold 6 best test acc: 0.9474\n",
            "\n",
            "=== Fold 7 ===\n",
            "torch.Size([38, 4]) torch.Size([17, 7])\n",
            "Epoch 001 | Train loss 0.8769 acc 0.6864 | Test loss 0.6078 acc 0.6316\n",
            "Epoch 020 | Train loss 0.3816 acc 0.7870 | Test loss 0.3139 acc 0.7895\n",
            "Epoch 040 | Train loss 0.3485 acc 0.8639 | Test loss 0.3680 acc 0.7895\n",
            "Epoch 060 | Train loss 0.3496 acc 0.8402 | Test loss 0.4936 acc 0.6842\n",
            "Epoch 080 | Train loss 0.2586 acc 0.8817 | Test loss 0.4715 acc 0.7895\n",
            "Epoch 100 | Train loss 0.2512 acc 0.8876 | Test loss 0.6613 acc 0.5789\n",
            "Fold 7 best test acc: 0.9474\n",
            "\n",
            "=== Fold 8 ===\n",
            "torch.Size([38, 4]) torch.Size([17, 7])\n",
            "Epoch 001 | Train loss 1.1664 acc 0.4911 | Test loss 0.6545 acc 0.6316\n",
            "Epoch 020 | Train loss 0.3372 acc 0.7929 | Test loss 0.6345 acc 0.7895\n",
            "Epoch 040 | Train loss 0.3312 acc 0.8639 | Test loss 0.6658 acc 0.7895\n",
            "Epoch 060 | Train loss 0.2692 acc 0.8935 | Test loss 0.5248 acc 0.8421\n",
            "Epoch 080 | Train loss 0.2173 acc 0.8994 | Test loss 0.2627 acc 0.8421\n",
            "Epoch 100 | Train loss 0.2704 acc 0.8935 | Test loss 0.5462 acc 0.6316\n",
            "Fold 8 best test acc: 0.9474\n",
            "\n",
            "=== Fold 9 ===\n",
            "torch.Size([38, 4]) torch.Size([17, 7])\n",
            "Epoch 001 | Train loss 0.9268 acc 0.5235 | Test loss 0.5947 acc 0.6667\n",
            "Epoch 020 | Train loss 0.3692 acc 0.8000 | Test loss 0.5222 acc 0.7222\n",
            "Epoch 040 | Train loss 0.3172 acc 0.8176 | Test loss 0.8109 acc 0.5000\n",
            "Epoch 060 | Train loss 0.2942 acc 0.8529 | Test loss 1.3553 acc 0.3333\n",
            "Epoch 080 | Train loss 0.2929 acc 0.8588 | Test loss 0.5870 acc 0.7222\n",
            "Epoch 100 | Train loss 0.2597 acc 0.8824 | Test loss 1.4279 acc 0.3333\n",
            "Fold 9 best test acc: 0.8333\n",
            "\n",
            "=== Fold 10 ===\n",
            "torch.Size([38, 4]) torch.Size([17, 7])\n",
            "Epoch 001 | Train loss 0.5361 acc 0.7059 | Test loss 0.5783 acc 0.6667\n",
            "Epoch 020 | Train loss 0.3364 acc 0.8706 | Test loss 0.6941 acc 0.6667\n",
            "Epoch 040 | Train loss 0.3345 acc 0.8647 | Test loss 0.9298 acc 0.6111\n",
            "Epoch 060 | Train loss 0.2698 acc 0.8765 | Test loss 0.3404 acc 0.8333\n",
            "Epoch 080 | Train loss 0.2139 acc 0.9176 | Test loss 0.4540 acc 0.8889\n",
            "Epoch 100 | Train loss 0.2116 acc 0.9059 | Test loss 0.7288 acc 0.7778\n",
            "Fold 10 best test acc: 0.8889\n",
            "\n",
            "10-fold CV accuracy: 0.9091 ± 0.0592\n"
          ]
        }
      ]
    }
  ]
}