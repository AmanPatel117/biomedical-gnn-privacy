{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip\n",
        "!pip3 install torch==2.3.1 --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip install torch_geometric\n",
        "!pip install torch_cluster torch_scatter -f https://data.pyg.org/whl/torch-2.3.1+cu121.html\n",
        "!pip install gdown"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WiPOxpz077AG",
        "outputId": "7cd8b350-51ed-4d68-a5c7-9f9ca0418622"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (25.3)\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Requirement already satisfied: torch==2.3.1 in /usr/local/lib/python3.12/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (4.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.1) (12.6.85)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.3.1) (3.0.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch==2.3.1) (1.3.0)\n",
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.12/dist-packages (2.7.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.13.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.22.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.12/dist-packages (from yarl<2.0,>=1.17.0->aiohttp->torch_geometric) (3.11)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch_geometric) (4.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch_geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2025.10.5)\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.3.1+cu121.html\n",
            "Requirement already satisfied: torch_cluster in /usr/local/lib/python3.12/dist-packages (1.6.3+pt23cu121)\n",
            "Requirement already satisfied: torch_scatter in /usr/local/lib/python3.12/dist-packages (2.1.2+pt23cu121)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from torch_cluster) (1.16.2)\n",
            "Requirement already satisfied: numpy<2.6,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from scipy->torch_cluster) (2.0.2)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown) (4.13.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown) (3.20.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.12/dist-packages (from gdown) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2025.10.5)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "O6DHFYuOuPMs"
      },
      "outputs": [],
      "source": [
        "!pip -q install --force-reinstall --no-deps fsspec==2023.6.0\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3HRLa8xybnD",
        "outputId": "a241d935-d76b-4c1c-9900-e3fe39e6082e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import random_split\n",
        "from torch_geometric.data import Data, InMemoryDataset, DataLoader\n",
        "from torch_geometric.nn import GINEConv, global_add_pool, global_mean_pool, global_max_pool\n",
        "from torch_geometric.utils import dense_to_sparse\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "from typing import List\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.cluster import KMeans\n",
        "import math, random\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhUf0C-6ul_7",
        "outputId": "a128ba6d-5c51-4870-9e9f-fdd2a974697a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dataset Preprocessing\n",
        "Doing node-level classification using a k-means synthetic feature"
      ],
      "metadata": {
        "id": "yoHTo7cQwVLf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "K = 3 #how many clusters to generate\n",
        "def preprocess_MUTAG(data: Data):\n",
        "  #create synthetic node-level labels with k-means clustering\n",
        "  node_labels = data.x.float()  # [N, D]\n",
        "  N, D = node_labels.shape\n",
        "\n",
        "  km = KMeans(n_clusters=K, n_init=10, random_state=0).fit(node_labels.numpy())\n",
        "  y_node = torch.from_numpy(km.labels_).long()\n",
        "  #add the graph label as a feature to all nodes\n",
        "  #graph_label = torch.unsqueeze(data.y, dim=0).repeat(N, 1)\n",
        "\n",
        "  #data.x = torch.cat((node_labels, graph_label.view(-1, 1)), dim=1)\n",
        "  #substitute in the node-level k-means labels\n",
        "  data.y = y_node\n",
        "  return data\n"
      ],
      "metadata": {
        "id": "W92eJmaVmKEe"
      },
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.datasets import TUDataset\n",
        "\n",
        "dataset = TUDataset(root='data/TUD', name='MUTAG', use_node_attr=True,pre_transform = preprocess_MUTAG,force_reload=True)  # 188 graphs\n",
        "sizes = [data.num_nodes for data in dataset]\n",
        "idx = int(np.argmax([n if n >= 25 else 0 for n in sizes]))  # pick a larger graph\n",
        "data = dataset[idx]\n",
        "print(f\"Graph index {idx}: nodes={data.num_nodes}, edges={data.num_edges // 2} (undirected)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjkjRtfjwFzi",
        "outputId": "9c75ca4b-2d65-40e3-a77b-0527ba2955d6"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph index 5: nodes=28, edges=31 (undirected)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = dataset[0]\n",
        "print(data)\n",
        "print(data.y)\n",
        "for data in dataset:\n",
        "  #print(max(data.y))\n",
        "  pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzM_eOE3lmx0",
        "outputId": "dd8a6752-0887-41ed-b1e3-e5a6e089df8c"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data(edge_index=[2, 38], x=[17, 7], edge_attr=[38, 4], y=[17])\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "dataset = TUDataset(root=\"data/TUDataset\", name=\"MUTAG\", use_node_attr=True)\n",
        "#MUTAG typically has node attributes; if not present, dataset.data.x may be None\n",
        "if dataset.num_node_features == 0:\n",
        "    #fallback: use one-hot of node labels if available, else create constant feature\n",
        "    if dataset.num_node_labels > 0:\n",
        "        print(\"No node features found — using node labels one-hot\")\n",
        "        #replace x by one-hot of node_label (PyG stores node labels in data.x sometimes)\n",
        "        for data in dataset:\n",
        "            #convert data.x (assumed scalar) to one-hot classification\n",
        "            if data.x is not None and data.x.dim() == 1:\n",
        "                num_cat = int(data.x.max().item()) + 1\n",
        "                one_hot = F.one_hot(data.x.long(), num_classes=num_cat).to(torch.float)\n",
        "                data.x = one_hot\n",
        "            else:\n",
        "                # create constant feature\n",
        "                data.x = torch.ones((data.num_nodes, 1), dtype=torch.float)\n",
        "    else:\n",
        "        for data in dataset:\n",
        "            data.x = torch.ones((data.num_nodes, 1), dtype=torch.float)\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "cfULAGd6wUqY",
        "outputId": "c060f0fc-400d-4357-e9ae-4218304b978c"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndataset = TUDataset(root=\"data/TUDataset\", name=\"MUTAG\", use_node_attr=True)\\n#MUTAG typically has node attributes; if not present, dataset.data.x may be None\\nif dataset.num_node_features == 0:\\n    #fallback: use one-hot of node labels if available, else create constant feature\\n    if dataset.num_node_labels > 0:\\n        print(\"No node features found — using node labels one-hot\")\\n        #replace x by one-hot of node_label (PyG stores node labels in data.x sometimes)\\n        for data in dataset:\\n            #convert data.x (assumed scalar) to one-hot classification\\n            if data.x is not None and data.x.dim() == 1:\\n                num_cat = int(data.x.max().item()) + 1\\n                one_hot = F.one_hot(data.x.long(), num_classes=num_cat).to(torch.float)\\n                data.x = one_hot\\n            else:\\n                # create constant feature\\n                data.x = torch.ones((data.num_nodes, 1), dtype=torch.float)\\n    else:\\n        for data in dataset:\\n            data.x = torch.ones((data.num_nodes, 1), dtype=torch.float)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GIN Model\n",
        "Customizable GINE model built around the pyg GINEConv layer. Use GINE over GIN to train on edge features"
      ],
      "metadata": {
        "id": "BFoAxU4FxoA2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EdgeMLP(nn.Module):\n",
        "    \"\"\"Small MLP to combine node and edge features inside each GINE layer.\"\"\"\n",
        "    def __init__(self, input_dim, hidden_dim, dropout=0.0):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class GINEModel(nn.Module):\n",
        "    def __init__(self, node_input_dim, edge_input_dim, hidden_dim=64,\n",
        "                 num_layers=3, dropout=0.2, num_node_classes=None):\n",
        "        super().__init__()\n",
        "        \"\"\"\n",
        "        GINE model for node classification\n",
        "        \"\"\"\n",
        "        self.num_layers = num_layers\n",
        "        self.convs = nn.ModuleList()\n",
        "        self.bns = nn.ModuleList()\n",
        "        self.edge_transform = nn.ModuleList()\n",
        "        for i in range(num_layers):\n",
        "            in_dim = node_input_dim if i == 0 else hidden_dim\n",
        "            mlp = EdgeMLP(in_dim, hidden_dim, dropout)\n",
        "            #don't explicitly define edge_dim here; transform edge features into\n",
        "            #the same dimension as the GINE in the forward pass with edge_layer\n",
        "            conv = GINEConv(nn=mlp, train_eps=True)\n",
        "            edge_layer = nn.Linear(edge_input_dim, in_dim)\n",
        "            self.convs.append(conv)\n",
        "            self.bns.append(nn.BatchNorm1d(hidden_dim))\n",
        "            self.edge_transform.append(edge_layer)\n",
        "\n",
        "        #Per-node classifier head\n",
        "        if num_node_classes is None:\n",
        "            #make a best guess from node features\n",
        "            num_node_classes = node_input_dim\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, num_node_classes)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
        "        if edge_attr is None:\n",
        "            #if dataset doesn’t have edge attributes, use zeros\n",
        "            edge_attr = torch.zeros((edge_index.size(1), 1), device=x.device)\n",
        "        for conv, bn, edge_transform in zip(self.convs, self.bns, self.edge_transform):\n",
        "            #transform edge features to match node input dimensions\n",
        "            edge_attr_trans = edge_transform(edge_attr)\n",
        "            x = conv(x, edge_index, edge_attr_trans)\n",
        "            x = bn(x)\n",
        "            x = F.relu(x)\n",
        "        #g = self.pool(x, batch)\n",
        "        logits = self.classifier(x)\n",
        "        return logits\n"
      ],
      "metadata": {
        "id": "Z0aPUAmMu1p2"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Utility Functions"
      ],
      "metadata": {
        "id": "cueyxjdSKFQo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, loader, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    correct = 0\n",
        "    total_nodes = 0\n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(data)  # shape [N_nodes_batch, C]\n",
        "        target = data.y.to(device).view(-1)\n",
        "\n",
        "        loss = F.cross_entropy(logits, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += float(loss.item()) * logits.size(0)\n",
        "        preds = logits.argmax(dim=1)\n",
        "        correct += int((preds == target).sum().item())\n",
        "        total_nodes += logits.size(0)\n",
        "    return total_loss / total_nodes, correct / total_nodes\n"
      ],
      "metadata": {
        "id": "4v_APjGPCUgQ"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(model, loader, device):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    correct = 0\n",
        "    total_nodes = 0\n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "        logits = model(data)\n",
        "        target = data.y.to(device).view(-1)\n",
        "        loss = F.cross_entropy(logits, target)\n",
        "        total_loss += float(loss.item()) * logits.size(0)\n",
        "        preds = logits.argmax(dim=1)\n",
        "        correct += int((preds == target).sum().item())\n",
        "        total_nodes += logits.size(0)\n",
        "    return total_loss / total_nodes, correct / total_nodes\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uMiiIB7dvBN3"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline Training & Evaluation"
      ],
      "metadata": {
        "id": "lXqrtRV5J6qL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from torch.utils.data import Subset\n",
        "\n",
        "#hyperparams\n",
        "train_frac = 0.8 #80/20 train-test split\n",
        "seed = 42\n",
        "epochs = 400\n",
        "batch_size = 32\n",
        "lr = 1e-3\n",
        "weight_decay = 1e-5\n",
        "#initialize random #s\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "indices = list(range(len(dataset)))\n",
        "#y = list(dataset[i].y for i in range(len(dataset)))\n",
        "#StratifiedKFold for cross-validation (90/10 train-test split each time)\n",
        "#skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "np.random.shuffle(indices)\n",
        "train_idx = indices[:int(len(indices) * train_frac)]\n",
        "test_idx = indices[:int(len(indices) * train_frac)]\n",
        "#split with subset\n",
        "train_subset = Subset(dataset, train_idx)\n",
        "test_subset = Subset(dataset, test_idx)"
      ],
      "metadata": {
        "id": "bXxpduBVpwg7"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_subset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "#initialize model from scratch\n",
        "model = GINEModel(node_input_dim=dataset[0].x.shape[1],\n",
        "                  edge_input_dim=dataset[0].edge_attr.shape[1],\n",
        "                  hidden_dim=32,\n",
        "                  num_layers=2,\n",
        "                  dropout=0.2,\n",
        "                  num_node_classes=K).to(device)\n",
        "optimizer = Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "best_test_acc = 0.0\n",
        "for epoch in range(1, epochs + 1):\n",
        "    train_loss, train_acc = train_epoch(model, train_loader, optimizer, device)\n",
        "    test_loss, test_acc = evaluate(model, test_loader, device)\n",
        "    if test_acc > best_test_acc:\n",
        "        best_test_acc = test_acc\n",
        "        torch.save(model.state_dict(), \"best_gine_node.pth\")\n",
        "    if epoch % 5 == 0 or epoch == 1 or epoch == epochs:\n",
        "        print(f\"Epoch {epoch:03d} | Train loss {train_loss:.4f} acc {train_acc:.4f} | Test loss {test_loss:.4f} acc {test_acc:.4f} (best {best_test_acc:.4f})\")\n",
        "\n",
        "print(\"Finished. Best test node acc:\", best_test_acc)\n",
        "#fold_accuracies.append(best_test_acc)\n",
        "\n",
        "#mean_acc = np.mean(fold_accuracies)\n",
        "#std_acc = np.std(fold_accuracies)\n",
        "#print(f\"\\n10-fold CV accuracy: {mean_acc:.4f} ± {std_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXgrKCfQJrT2",
        "outputId": "426217ef-d8be-460e-b646-992f26c0ebbd"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-766228377.py:1: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
            "/tmp/ipython-input-766228377.py:2: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  test_loader = DataLoader(test_subset, batch_size=batch_size, shuffle=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 001 | Train loss 1.0532 acc 0.5816 | Test loss 1.0855 acc 0.6457 (best 0.6457)\n",
            "Epoch 005 | Train loss 0.8560 acc 0.7146 | Test loss 1.0064 acc 0.6330 (best 0.6577)\n",
            "Epoch 010 | Train loss 0.6891 acc 0.7326 | Test loss 0.8721 acc 0.6790 (best 0.6790)\n",
            "Epoch 015 | Train loss 0.6279 acc 0.7543 | Test loss 0.7584 acc 0.7749 (best 0.7749)\n",
            "Epoch 020 | Train loss 0.5922 acc 0.7678 | Test loss 0.6252 acc 0.7757 (best 0.7779)\n",
            "Epoch 025 | Train loss 0.5726 acc 0.7730 | Test loss 0.5894 acc 0.7820 (best 0.7820)\n",
            "Epoch 030 | Train loss 0.5578 acc 0.7809 | Test loss 0.6436 acc 0.7891 (best 0.7903)\n",
            "Epoch 035 | Train loss 0.5497 acc 0.7858 | Test loss 0.6109 acc 0.7940 (best 0.7944)\n",
            "Epoch 040 | Train loss 0.5467 acc 0.7876 | Test loss 0.6447 acc 0.7921 (best 0.7944)\n",
            "Epoch 045 | Train loss 0.5420 acc 0.7865 | Test loss 0.5775 acc 0.7921 (best 0.7944)\n",
            "Epoch 050 | Train loss 0.5292 acc 0.7899 | Test loss 0.6000 acc 0.7944 (best 0.7948)\n",
            "Epoch 055 | Train loss 0.5384 acc 0.7891 | Test loss 0.6116 acc 0.7854 (best 0.7970)\n",
            "Epoch 060 | Train loss 0.5318 acc 0.7888 | Test loss 0.5753 acc 0.7944 (best 0.7970)\n",
            "Epoch 065 | Train loss 0.5213 acc 0.7921 | Test loss 0.5239 acc 0.7955 (best 0.7970)\n",
            "Epoch 070 | Train loss 0.5262 acc 0.7970 | Test loss 0.5720 acc 0.8030 (best 0.8030)\n",
            "Epoch 075 | Train loss 0.5261 acc 0.7933 | Test loss 0.5422 acc 0.8015 (best 0.8030)\n",
            "Epoch 080 | Train loss 0.5172 acc 0.7918 | Test loss 0.8325 acc 0.6554 (best 0.8082)\n",
            "Epoch 085 | Train loss 0.5319 acc 0.7966 | Test loss 0.5897 acc 0.8082 (best 0.8090)\n",
            "Epoch 090 | Train loss 0.5220 acc 0.7959 | Test loss 0.5342 acc 0.8041 (best 0.8090)\n",
            "Epoch 095 | Train loss 0.5211 acc 0.7948 | Test loss 0.5368 acc 0.8052 (best 0.8109)\n",
            "Epoch 100 | Train loss 0.5150 acc 0.8004 | Test loss 0.5210 acc 0.8022 (best 0.8109)\n",
            "Epoch 105 | Train loss 0.5180 acc 0.8011 | Test loss 0.5361 acc 0.8120 (best 0.8120)\n",
            "Epoch 110 | Train loss 0.5097 acc 0.7981 | Test loss 0.5182 acc 0.8086 (best 0.8120)\n",
            "Epoch 115 | Train loss 0.5064 acc 0.8000 | Test loss 0.5244 acc 0.8097 (best 0.8120)\n",
            "Epoch 120 | Train loss 0.5200 acc 0.7970 | Test loss 0.5393 acc 0.8030 (best 0.8120)\n",
            "Epoch 125 | Train loss 0.5089 acc 0.8019 | Test loss 0.5202 acc 0.8052 (best 0.8120)\n",
            "Epoch 130 | Train loss 0.5130 acc 0.7989 | Test loss 0.4984 acc 0.8045 (best 0.8139)\n",
            "Epoch 135 | Train loss 0.5142 acc 0.7996 | Test loss 0.5474 acc 0.8067 (best 0.8139)\n",
            "Epoch 140 | Train loss 0.5056 acc 0.8060 | Test loss 0.4886 acc 0.8109 (best 0.8139)\n",
            "Epoch 145 | Train loss 0.5056 acc 0.8026 | Test loss 0.5113 acc 0.8135 (best 0.8139)\n",
            "Epoch 150 | Train loss 0.5020 acc 0.8019 | Test loss 0.4854 acc 0.8109 (best 0.8139)\n",
            "Epoch 155 | Train loss 0.4990 acc 0.8045 | Test loss 0.5199 acc 0.8154 (best 0.8154)\n",
            "Epoch 160 | Train loss 0.5104 acc 0.8004 | Test loss 0.4884 acc 0.8079 (best 0.8154)\n",
            "Epoch 165 | Train loss 0.5008 acc 0.8030 | Test loss 0.5411 acc 0.8094 (best 0.8154)\n",
            "Epoch 170 | Train loss 0.5070 acc 0.8034 | Test loss 0.5097 acc 0.8127 (best 0.8154)\n",
            "Epoch 175 | Train loss 0.4889 acc 0.8064 | Test loss 0.4993 acc 0.8120 (best 0.8154)\n",
            "Epoch 180 | Train loss 0.5068 acc 0.8064 | Test loss 0.5028 acc 0.8146 (best 0.8154)\n",
            "Epoch 185 | Train loss 0.4979 acc 0.8067 | Test loss 0.5177 acc 0.8131 (best 0.8154)\n",
            "Epoch 190 | Train loss 0.5113 acc 0.7996 | Test loss 0.4939 acc 0.8090 (best 0.8154)\n",
            "Epoch 195 | Train loss 0.5068 acc 0.7993 | Test loss 0.4839 acc 0.8116 (best 0.8154)\n",
            "Epoch 200 | Train loss 0.4979 acc 0.8037 | Test loss 0.4887 acc 0.8131 (best 0.8154)\n",
            "Epoch 205 | Train loss 0.5063 acc 0.8049 | Test loss 0.5022 acc 0.8041 (best 0.8154)\n",
            "Epoch 210 | Train loss 0.5017 acc 0.8019 | Test loss 1.3142 acc 0.6700 (best 0.8154)\n",
            "Epoch 215 | Train loss 0.5086 acc 0.7974 | Test loss 0.5126 acc 0.8067 (best 0.8154)\n",
            "Epoch 220 | Train loss 0.4981 acc 0.8064 | Test loss 0.5041 acc 0.8000 (best 0.8154)\n",
            "Epoch 225 | Train loss 0.5147 acc 0.8019 | Test loss 0.4953 acc 0.8124 (best 0.8154)\n",
            "Epoch 230 | Train loss 0.5078 acc 0.8030 | Test loss 0.5080 acc 0.8135 (best 0.8165)\n",
            "Epoch 235 | Train loss 0.4982 acc 0.8056 | Test loss 0.4964 acc 0.8105 (best 0.8165)\n",
            "Epoch 240 | Train loss 0.4919 acc 0.8079 | Test loss 0.5026 acc 0.8131 (best 0.8165)\n",
            "Epoch 245 | Train loss 0.5163 acc 0.8041 | Test loss 0.5137 acc 0.8127 (best 0.8165)\n",
            "Epoch 250 | Train loss 0.4934 acc 0.8060 | Test loss 0.4881 acc 0.8086 (best 0.8165)\n",
            "Epoch 255 | Train loss 0.4896 acc 0.8071 | Test loss 0.5070 acc 0.8142 (best 0.8165)\n",
            "Epoch 260 | Train loss 0.5029 acc 0.8075 | Test loss 0.4848 acc 0.8139 (best 0.8165)\n",
            "Epoch 265 | Train loss 0.4978 acc 0.8079 | Test loss 0.5053 acc 0.8105 (best 0.8165)\n",
            "Epoch 270 | Train loss 0.4923 acc 0.8049 | Test loss 0.4808 acc 0.8097 (best 0.8165)\n",
            "Epoch 275 | Train loss 0.5095 acc 0.8056 | Test loss 0.4896 acc 0.8142 (best 0.8165)\n",
            "Epoch 280 | Train loss 0.4936 acc 0.8090 | Test loss 0.5128 acc 0.7989 (best 0.8176)\n",
            "Epoch 285 | Train loss 0.4918 acc 0.8094 | Test loss 0.5007 acc 0.8150 (best 0.8176)\n",
            "Epoch 290 | Train loss 0.4910 acc 0.8052 | Test loss 0.5013 acc 0.8131 (best 0.8176)\n",
            "Epoch 295 | Train loss 0.4905 acc 0.8082 | Test loss 0.4789 acc 0.8131 (best 0.8176)\n",
            "Epoch 300 | Train loss 0.4951 acc 0.8135 | Test loss 0.4917 acc 0.8161 (best 0.8176)\n",
            "Epoch 305 | Train loss 0.4887 acc 0.8150 | Test loss 0.4925 acc 0.8154 (best 0.8176)\n",
            "Epoch 310 | Train loss 0.4829 acc 0.8090 | Test loss 0.4793 acc 0.8154 (best 0.8176)\n",
            "Epoch 315 | Train loss 0.4910 acc 0.8135 | Test loss 0.4843 acc 0.8154 (best 0.8176)\n",
            "Epoch 320 | Train loss 0.4847 acc 0.8146 | Test loss 0.4945 acc 0.8154 (best 0.8176)\n",
            "Epoch 325 | Train loss 0.4920 acc 0.8135 | Test loss 0.4965 acc 0.8007 (best 0.8176)\n",
            "Epoch 330 | Train loss 0.5014 acc 0.8064 | Test loss 0.4756 acc 0.8172 (best 0.8176)\n",
            "Epoch 335 | Train loss 0.4854 acc 0.8124 | Test loss 0.4832 acc 0.8154 (best 0.8213)\n",
            "Epoch 340 | Train loss 0.4891 acc 0.8124 | Test loss 0.4865 acc 0.8169 (best 0.8213)\n",
            "Epoch 345 | Train loss 0.4828 acc 0.8127 | Test loss 0.4806 acc 0.8124 (best 0.8213)\n",
            "Epoch 350 | Train loss 0.4879 acc 0.8142 | Test loss 0.4770 acc 0.8184 (best 0.8213)\n",
            "Epoch 355 | Train loss 0.4866 acc 0.8131 | Test loss 0.4913 acc 0.8172 (best 0.8213)\n",
            "Epoch 360 | Train loss 0.4890 acc 0.8109 | Test loss 0.4764 acc 0.8131 (best 0.8213)\n",
            "Epoch 365 | Train loss 0.4880 acc 0.8082 | Test loss 0.4760 acc 0.8161 (best 0.8213)\n",
            "Epoch 370 | Train loss 0.5003 acc 0.8049 | Test loss 0.4946 acc 0.8165 (best 0.8213)\n",
            "Epoch 375 | Train loss 0.4798 acc 0.8116 | Test loss 0.4934 acc 0.8124 (best 0.8213)\n",
            "Epoch 380 | Train loss 0.4842 acc 0.8116 | Test loss 0.4716 acc 0.8176 (best 0.8213)\n",
            "Epoch 385 | Train loss 0.4872 acc 0.8105 | Test loss 0.4852 acc 0.8161 (best 0.8213)\n",
            "Epoch 390 | Train loss 0.4845 acc 0.8139 | Test loss 0.4695 acc 0.8172 (best 0.8213)\n",
            "Epoch 395 | Train loss 0.4853 acc 0.8112 | Test loss 0.4845 acc 0.8030 (best 0.8213)\n",
            "Epoch 400 | Train loss 0.4964 acc 0.8052 | Test loss 0.4758 acc 0.8157 (best 0.8213)\n",
            "Finished. Best test node acc: 0.8213483146067416\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LINKTELLER Attack"
      ],
      "metadata": {
        "id": "sF6i1gDHXJ0i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "NqXojWCbbYfa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy as sp\n",
        "class Linkteller():\n",
        "      def __init__(self, model, device, test_node_feats, test_edge_idx,\n",
        "                   test_edge_attr = None):\n",
        "        \"\"\"\n",
        "        model: Pretrained model\n",
        "        device: torch.device\n",
        "        test_edge_idx: adjacency matrix for the graph being evaluated\n",
        "        undirected: whether the graph is undirected or not (default: True)\n",
        "        \"\"\"\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "        #graph dataset node features\n",
        "        self.test_node_feats = test_node_feats\n",
        "        self.num_nodes = test_node_feats.shape[0]\n",
        "        self.test_edge_idx = test_edge_idx\n",
        "        self.test_edge_attr = test_edge_attr\n",
        "        #build adjcency matrix for test graph from edge indices\n",
        "        self.test_adj = torch.zeros((self.num_nodes, self.num_nodes), dtype=torch.float)\n",
        "        self.test_adj[test_edge_idx[0], test_edge_idx[1]] = True\n",
        "        self.test_adj[test_edge_idx[1], test_edge_idx[0]] = True\n",
        "        self.test_adj.fill_diagonal_(False)\n",
        "        self.true_edges_undirected = torch.nonzero(torch.triu(self.test_adj,\n",
        "                                                         diagonal=1),\n",
        "                                              as_tuple=False)  # [M, 2]\n",
        "        self.M_true = self.true_edges_undirected.shape[0]\n",
        "        self.density = self.M_true / (self.num_nodes*(self.num_nodes-1)/2)\n",
        "\n",
        "      @torch.no_grad()\n",
        "      def gbb_api(self, node_ids, X_query):\n",
        "          \"\"\"\n",
        "          node_ids: 1D LongTensor of node indices to fetch from output\n",
        "          X_query: (N, D) full feature matrix Bob provides (Alice uses it with her private edge_index)\n",
        "          returns: logits[node_ids] shape (len(node_ids), K)\n",
        "\n",
        "          modified from Linkteller.ipynb\n",
        "          \"\"\"\n",
        "          model.eval()\n",
        "          #reconstruct graph using Bob's provided node features & Alice's edges\n",
        "          if self.test_edge_attr is None:\n",
        "            test_graph = Data(x=X_query, edge_index=self.test_edge_idx)\n",
        "          else:\n",
        "            test_graph = Data(x=X_query,\n",
        "                              edge_index=self.test_edge_idx,\n",
        "                              edge_attr=self.test_edge_attr)\n",
        "          test_graph = test_graph.to(device)\n",
        "          out = model(test_graph)\n",
        "          return out[node_ids.to(device)].detach().cpu()\n",
        "\n",
        "      def influence_matrix_for_v(self,v, V_I, X_base, delta=1e-2):\n",
        "          \"\"\"\n",
        "          v: node index (int)\n",
        "          V_I: 1D LongTensor of nodes-of-interest to score against\n",
        "          X_base: (N, D) baseline features\n",
        "          returns: Iv (|V_I|, K) = (P' - P)/delta where rows correspond to u in V_I\n",
        "          \"\"\"\n",
        "          node_ids = V_I\n",
        "          P = self.gbb_api(node_ids, X_base)\n",
        "\n",
        "          Xp = X_base.clone()\n",
        "          Xp[v] = (1.0 + delta) * Xp[v]  # upweight features of v\n",
        "          Pp = self.gbb_api(node_ids, Xp)\n",
        "\n",
        "          Iv = (Pp - P) / delta  # finite-diff approximation\n",
        "          return Iv  # (|V_I|, K)\n",
        "\n",
        "      def linkteller_scores(self, V_C, X_base, delta=1e-2):\n",
        "          \"\"\"\n",
        "          V_C: nodes-of-interest (attack surface) as 1D LongTensor\n",
        "          returns: dict {(u,v): score} for u != v, unordered pairs\n",
        "          \"\"\"\n",
        "          V_C = V_C.cpu()\n",
        "          scores = {}\n",
        "          for j, v in enumerate(V_C.tolist()):\n",
        "              # rows aligned with V_C\n",
        "              Iv = self.influence_matrix_for_v(v,\n",
        "                                               V_C,\n",
        "                                               X_base,\n",
        "                                               delta=delta).numpy()\n",
        "              # influence value of v on each u = ||Iv[u,:]||_2\n",
        "              norms = np.linalg.norm(Iv, axis=1)\n",
        "              for i, u in enumerate(V_C.tolist()):\n",
        "                  if u == v:\n",
        "                      continue\n",
        "                  key = (min(u,v), max(u,v))\n",
        "                  # symmetrical score: max of v→u and u→v will be handled later; accumulate max\n",
        "                  scores[key] = max(scores.get(key, 0.0), float(norms[i]))\n",
        "          return scores\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "G8ATmYCZXyNF"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pick larger graph\n",
        "sizes = [data.num_nodes for data in dataset]\n",
        "idx = int(np.argmax([n if n >= 25 else 0 for n in sizes]))  # pick a larger graph\n",
        "\n",
        "test_graph = dataset[idx]\n",
        "linkteller_MUTAG_GIN = Linkteller(model = model,\n",
        "                                  device=device,\n",
        "                                  test_node_feats=test_graph.x,\n",
        "                                  test_edge_idx=test_graph.edge_index,\n",
        "                                  test_edge_attr=test_graph.edge_attr)\n"
      ],
      "metadata": {
        "id": "mG15tLoQXkCA"
      },
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose attack node set V_C (we’ll use all nodes to make life easy)\n",
        "N = test_graph.x.shape[0]\n",
        "V_C = torch.arange(N, dtype=torch.long)\n",
        "X = test_graph.x\n",
        "scores = linkteller_MUTAG_GIN.linkteller_scores(V_C, X, delta=1e-2)\n",
        "\n",
        "# Turn scores into a sorted list\n",
        "sorted_pairs = sorted(scores.items(), key=lambda kv: kv[1], reverse=True)\n",
        "len(sorted_pairs), sorted_pairs[:5]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bSIb_1etVEA",
        "outputId": "fec95852-4e0f-4305-8024-f41db6d41d5a"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(378,\n",
              " [((7, 8), 6.03274393081665),\n",
              "  ((8, 13), 6.03274393081665),\n",
              "  ((2, 7), 6.032741069793701),\n",
              "  ((6, 7), 6.032741069793701),\n",
              "  ((8, 9), 6.032741069793701)])"
            ]
          },
          "metadata": {},
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = N\n",
        "m_true = linkteller_MUTAG_GIN.M_true\n",
        "m_belief = int(round(linkteller_MUTAG_GIN.density * (n*(n-1)/2)))\n",
        "\n",
        "pred_edges = set([pair for (pair, _) in sorted_pairs[:m_belief]])\n",
        "\n",
        "# ground truth undirected edges as set of tuples (i,j) with i<j\n",
        "true_edges = set([tuple(e.tolist()) for e in linkteller_MUTAG_GIN.true_edges_undirected])\n",
        "\n",
        "tp = len(pred_edges & true_edges)\n",
        "fp = len(pred_edges - true_edges)\n",
        "fn = len(true_edges - pred_edges)\n",
        "\n",
        "precision = tp / (tp + fp + 1e-12)\n",
        "recall    = tp / (tp + fn + 1e-12)\n",
        "f1        = 2*precision*recall / (precision + recall + 1e-12)\n",
        "print(f\"Precision={precision:.3f} | Recall={recall:.3f} | F1={f1:.3f} | m_belief={m_belief} | true M={m_true}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nw6jCz5FuVwv",
        "outputId": "49795367-d99c-45d1-9af2-45ee9ce62901"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision=0.419 | Recall=0.419 | F1=0.419 | m_belief=31 | true M=31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_at_fraction(frac):\n",
        "    m = int(round(frac * (n*(n-1)/2)))\n",
        "    pred = set([pair for (pair, _) in sorted_pairs[:m]])\n",
        "    tp = len(pred & true_edges)\n",
        "    fp = len(pred - true_edges)\n",
        "    fn = len(true_edges - pred)\n",
        "    p = tp / (tp + fp + 1e-12)\n",
        "    r = tp / (tp + fn + 1e-12)\n",
        "    f1 = 2*p*r / (p + r + 1e-12)\n",
        "    return p, r, f1, m\n",
        "density = linkteller_MUTAG_GIN.density\n",
        "for frac in [0.5*density, 0.8*density, density, 1.2*density, 1.5*density]:\n",
        "    p, r, f1, m = evaluate_at_fraction(frac)\n",
        "    print(f\"k_hat={frac:.4f}  m={m:3d}  P={p:.3f} R={r:.3f} F1={f1:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9I6lzwRsuYKp",
        "outputId": "ab068fe3-dc5a-479f-c706-8e991209da72"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k_hat=0.0410  m= 16  P=0.312 R=0.161 F1=0.213\n",
            "k_hat=0.0656  m= 25  P=0.360 R=0.290 F1=0.321\n",
            "k_hat=0.0820  m= 31  P=0.419 R=0.419 F1=0.419\n",
            "k_hat=0.0984  m= 37  P=0.459 R=0.548 F1=0.500\n",
            "k_hat=0.1230  m= 46  P=0.413 R=0.613 F1=0.494\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores_different_delta = linkteller_MUTAG_GIN.linkteller_scores(V_C, X, delta=5e-3)\n",
        "sorted_pairs_2 = sorted(scores_different_delta.items(), key=lambda kv: kv[1], reverse=True)\n",
        "pred_edges_2 = set([pair for (pair, _) in sorted_pairs_2[:m_belief]])\n",
        "\n",
        "tp2 = len(pred_edges_2 & true_edges)\n",
        "fp2 = len(pred_edges_2 - true_edges)\n",
        "fn2 = len(true_edges - pred_edges_2)\n",
        "p2 = tp2 / (tp2 + fp2 + 1e-12)\n",
        "r2 = tp2 / (tp2 + fn2 + 1e-12)\n",
        "f12 = 2*p2*r2 / (p2 + r2 + 1e-12)\n",
        "print(f\"(Δ=5e-3) Precision={p2:.3f} | Recall={r2:.3f} | F1={f12:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARw29yrKu1Ih",
        "outputId": "693a3e17-ca71-419e-95fb-0c9c0d61e801"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Δ=5e-3) Precision=0.355 | Recall=0.355 | F1=0.355\n"
          ]
        }
      ]
    }
  ]
}